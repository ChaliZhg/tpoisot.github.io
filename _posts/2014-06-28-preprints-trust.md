---
title: Preprints, and the issue of (misplaced) trust
layout: post
author: Tim
tags:
   - open science
   - preprints
   - peer review
---

Yesterday, a bunch of people (and I) were discussing what type of contributions
to list in your CV when you are looking for a job. Papers that are in press,
and accepted clearly belong here, but the discussion revolved around preprints
quite fast. I suggested to include them, and I got generally negative feedback:

<blockquote class="twitter-tweet" lang="en"><p><a href="https://twitter.com/tpoi">@tpoi</a> <a href="https://twitter.com/ProfLikeSubst">@ProfLikeSubst</a> <a href="https://twitter.com/GenomeDaddy">@GenomeDaddy</a> if you have an acceptance letter from an editor, sure put it on there. otherwise, no. <a href="https://twitter.com/hashtag/inmyworld?src=hash">#inmyworld</a></p>&mdash; Hope Jahren (@HopeJahren) <a href="https://twitter.com/HopeJahren/statuses/482608451319644163">June 27, 2014</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

Most of the discussion that followed was about the fact that, unless something
is published in a peer-reviewed journal, it's moot and should not be accounted
for. There are two assumptions behind that, and both of them are wrong. First,
that you should not trust anything unless it is peer-reviewed. Second, that
the peer-review process is the only thing standing between us and bad science.

As I suggested later in the discussion, people that don't trust the results
in a preprint should leave the room during talks based on unpublished
results. These have not been peer-reviewed, either. I half-suspect that
the fact that (in biological sciences) conferences are a more established
medium for the presentation of new scientific results than preprints
(despite being arguably worse for that), people are more willing to trust
12 minutes of un-reviewed talk than 12 pages of an un-reviewed paper by
the same person. Let's file that under "inertia", and let's get back to the
issue of conditionning whether or not we trust a paper on its position in
the editorial pipeline.

Assuming that published papers can be trusted is making the hypothesis
that peer-review is good at catching bad papers. Additionally, some people
raised the argument that the more *reputable* the journal (read: high
impact factor), the more confident we can be in the paper. That is not true
[@bre13]. It is a well established fact that high-impact journals tend to have
a higher retraction rate than low-impact journals. The very places where some
expect to see the most outsanding review process are involved in a "scandal"
every month or so, these days (arsenic DNA, stem cells, and the track record
goes back all the way to the memory of water). But even without considering
the *prestige* of a journal, there is this thing with absolute statements
(*Peer-reviewed papers count for something*): a counter-example is enough
to make them moot. There have been counter-examples enough that, although a
peer-reviewed paper *may be* trusted, you still have to find out for yourself
(by reading it).

And if the way to know if something, anything, is a good piece of scientific
litterature is to read it, then what is the difference between reading
a pre-print and a reviewed paper? As I said a few times, it's not that I
don't trust the peer-review process, it's that I trust my own critical sense
more. I'm not going to blindly trust a paper because it has been stamped as
good by a journal and two to five people I don't know, and I'm not going to
distrust a paper because it has not been through the same process. Neglecting
the results of my colleagues, or blindly trusting them because I expect others
to do the critical thinking for me, are I think equally irresponsible. But
Karthik said it best:

<blockquote class="twitter-tweet" lang="en"><p><a href="https://twitter.com/tpoi">@tpoi</a> I&#39;ll consider it word of god as soon as two busy reviewers have given it a cursory glance and a 3rd has been a total jerk about it.</p>&mdash; Karthik Ram (@_inundata) <a href="https://twitter.com/_inundata/statuses/482629845348651008">June 27, 2014</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

Of course *most* of the idea is that peer-review is a filter between us and
bad science. I don't know how many papers I have reviewed in the last 4 years,
I would be tempted to say about 25+ (not counting the one I reviewed multiple
times). There are two of these I found terrible. Of these two terrible papers,
*one* was "wrong", not even in the sense that they got the bases wrong, but
it was just severely incomplete. And so you don't start thinking that I'm
a really nice referee that is always happy about everythinAnd so you don't
start thinking that I'm a really nice referee that is always happy about
everything: I'm not; there are (I think) two instances where I recommended
something good and the paper ended up being rejected. But even though, my own
experience places the probability of a paper being terrible at approximately
0.04. I'm happy to take that chance if it means that I'll be reading the
cool stuff a year or so before it makes it through the review process.

But more broadly, there is a very disturbing thing behind the idea that
peer-review is such an essential filter: authors can't be trusted, and only
referees are to thank for such great science being published (and also for
making us spend another round in review to jump through many many hoops
to satisfy their own personal biases as they yield a ridiculous amount of
power). In addition, people using preprints are in the "whackadoodles" in the
eyes of some, as opposed to people that took the time to formulate a strong
case for preprints, and got it published in a *reputable* journal [@des13] --
which, for the record, do not mean you should blindly trust us. But express
your disagreement with an argumentation, not with a "That's the way it is"
or a cheap insult.
