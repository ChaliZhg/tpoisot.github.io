---
layout: post
title: The ecological journal of the future
summary: blog
chapo: What should the next generation of ecological journals look like?
author: Tim
type: essay
tags:
- scientific publishing
- open access
- next-gen science
---

I've been reading [Tim Gowers's fascinating blog](http://gowers.wordpress.com/2012/01/29/whats-wrong-with-electronic-journals/) following the call to boycott Elsevier, and stumbled upon a fascinating *gedankenexperiment*. What would the electronic journal of the future look like in the field of Mathematics? I found myself wondering, what would this next-generation journal look like in ecology, and how would it function on a daily basis?

I have been thinking about this for the last few months (the earliest draft of this text dates back to early in february), and got great feedback from some [INNGE](http://www.innge.net/) folks. Just for the sake of clarity, I am not saying that this new hypothetical journal *should* exist. I'm trying to imagine how I would do it in a perfect world, or in more ecological terms, what would be its «ideal free distribution».

# What's in a name?

If you want your journal to reflect a new paradigm, it should start with the way it's named. Phytologists have the *New Phytologist*. A lot of disciplines have *Advances in a lot of disciplines*. *Trends Ecol Evol* and *Frontiers Ecol Env* apart, the ecological journals are rather conservative in their naming. We have *Ecology* declined in as many languages as possible, followed by, or following some variation of *Letters*, *Journal of [prefix]*, *Research*, and so on. No *New*, no *Advances*. I'm absolutely not saying that ecological research is opposed to progress, it's clearly a field being moved forward by people with ten new ideas a day. But the names of the journals do not reflect that. The two publications who do (*TREE* and *FEE*) have such a specific editorial line that they can't possibly contain all of the new, exciting stuff.

By being clear about the fact that the journal seeks to explore new horizons, not only in terms of the science, but in terms of how it is managed on a daily basis (which forms the core of this modest proposal), a strong identity will be established, and people will come there knowing what to expect. I like Tim Gower's idea of *Breakthrough in ...*, which adds the notion that research reported here is timely, hot off the press results and ideas that deserves to be spread rapidly to the community. That being said, most of the impact that next-gen practices can make are not related to the name of the journal, but to the way it is conceived — name it *Good ol'Ecology* if it pleases you, but bring fresh ideas about the way it works.

# Paper-free papers

One of the main reason editors use when declining your paper is "constraints on the number of pages". This just in: some journals are still printed on dead trees. But when is the last time you actually read one of those? I'm not talking about taking a trip to the library to read a paper published in an obscure journal in the early 1950s. With the exception of free issues you collect at meetings, have you ever preferred the paper over the PDF version of an article? If my own habits are of any indication, I'm guessing no.

Note that switching to e-articles will not necessarily mean that constraints will be lifted. When reading the [instructions for authors at *Am. Nat.*](http://www.jstor.org/page/journal/amernatu/forAuthor.html) - and in all likelihood, some other journals with an e-paper alternative are doing it as well, it just so happenned that I was submitting something to *Am Nat* at the time - , I found this (emphasis mine):

> The choice of appearing as an open access e-article is available to all authors, **though the number that can appear with each issue are limited**.  

Sounds an awful lot as [artificial scarcity](http://en.wikipedia.org/wiki/Artificial_scarcity) to me, and the reason for which to do it is immediately clear: if the number of papers is limited, you will reject average-to-good papers and publish only the *crème de la crème* (french expression for super best - we rightfully consider cream to be one of the best things ever). Ergo, your impact factor, citation half-life, immediacy index, and all the others will all go up (or down - in any case, they'll go where you want them to). This is all fair and well (although I'll get back to why we should pay less and less attention to these metrics in the next section), but be upfront about it!

I should note that for this point, we have the technology. It's possible to have a good experience reading an e-paper. We have large screens to read the papers in the lab, and we can carry a copy of our library at all time with us on various mobile devices. Annotations are easy to add and to share with a tool like *Mendeley*, and [the *Nature Publishing Group* integrated with *ReadCube*](http://blog.readcube.com/post/12244190503/great-news-readcube-has-integrated) to annotate PDFs online. The later case delivers a particularly stunning experience. Paper-free journals are possible, [some of them allow you to order reprints of a paper](http://www.plosone.org/home.action), and the next generation of ecological journals should definitely follow this path.

# Quality, and surrogates of quality

Impact factors are a measure of the absolute success of a journal in its field. Yet we all know examples of papers published in really good journals that met a terrible fate (think arsenic in the DNA, the memory of water), or excellent papers that were consistently rejected by major journals (e.g. Leigh van Valen's [Red Queen's hypothesis](http://en.wikipedia.org/wiki/Red_Queen%27s_Hypothesis)). Some papers were also just completely ignored by their expected target community. Conversely, papers published in obscure journals can really be [hidden jewels](http://f1000.com/rankings/hiddenjewels), that will either get highly cited, or be really influential for your research. And this is entirely different.

For this reason, a next-generation journal should rely heavily on article-level metrics. [*PLoS One*](http://www.plosone.org/home.action) does that, and to some extent so does [Mendeley](http://www.mendeley.com/) through [ReaderMeter](http://nitens.org/taraborelli/ReaderMeter). What would these article-level metrics consist of? The number of downloads, or inclusions in Mendeley or similar services, and the number of citations. And much more importantly, the ratio between these two. With dead-trees publishing, you do not have access to this information, because what interest you is the number of people receiving a physical copy of a whole issue. Which paper they choose to read, and which they choose to ignore, is not something you can know and monitor. But with the transition to electronic publishing came the log file, and the number of times the link to a pdf was clicked is now readily available. On a side note, I'm taking a wild guess here, but if we assume that the major publishing services keep their logs for a long time, we can actually measure this ratio for already published papers. But how to interpretate it? If two people download your paper, and they both cite it 3 times, then it can safely be assumed that it had a different kind of impact than a paper downloaded by 150 people, and cited only twice. Not only would it tell you the total impact of this paper, article level metrics would inform you about the kind of impact it achieved.

Heather Piwowar and colleagues have been doing this analysis on *PLoS One* articles published over the last five years, and not surprisingly, they found that the [number of citation is a poor measure of the impact of a paper](http://blogs.lse.ac.uk/impactofsocialsciences/2012/04/04/31-flavours-research-impact/). Having the best possible metrics for impact and quality is a service to your readers, as it will help you crowd-source the evaluation paper; the referees (but more on that in a moment) will tell if the paper is sound, but the readers and other scientists will tell if it's *good*. Or relevant. Oh, and by the way, you can stop putting your 10-years half-life forward. It means your journal was good, 10 years ago. In a world when 10 new papers relevant to your research are published each day, and the people evaluating you care about your current impact factor, not your potential one in a few years, I'm wondering what the relevance of this metric is...

# Avoid the tragedy of the commons

A lot of people talked about the [tragedy of the reviewer commons](http://blogs.helsinki.fi/egru-blog/2008/12/20/the-tragedy-of-the-reviewer-commons/), including [Mike Hochberg and colleagues](http://onlinelibrary.wiley.com/doi/10.1111/j.1461-0248.2008.01276.x/abstract), [Jeremy Fox & Owen Petchey](http://www.esajournals.org/doi/pdf/10.1890/0012-9623-91.3.325) and [Michael Donaldson](http://library.queensu.ca/ojs/index.php/IEE/article/view/4219/4240), and I really cannot stress enough how reading these papers is important. Avoiding this "tragedy", which [seems to affect women even more](http://oikosjournal.wordpress.com/2012/03/19/may-the-odds-be-ever-in-your-favor-a-brief-comment-on-the-review-games-in-ecology/), can be quite easily done, if a new journal is ready to tap into an existing community of people *willing* to conduct peer-reviews.

For this reason, a next-generation journal should engage with [Peerage of Science](http://www.peerageofscience.org/). As we discussed on [the INNGE blog](http://innge.net/?q=node/121), they provide an easy way to obtain triple-blind peer-review in a way that is independent from the journal. I'm not a quite fan of triple-blind (or any other n-blind, for that matters) review process, because I strongly believe that [non-anonymous reviews can turn out to be beneficial](http://timotheepoisot.fr/2012/01/29/sign-your-reviews/), if properly done. In any case, turning to a system like *Peerage of Science* allows the authors to seek reviews with no prejudice associated with rejection. In addition, members from the editorial board can look for papers with good reviews, and offer the authors to publish them if they think the subject fits.

This can go even further by having a very flexible definition of what constitutes the editorial board. The process of looking for papers having recently recevied good reviews can very easily be crowd-sourced: any one should be able to propose/endorse a paper to the editors. This is the ultimate community-building of a journal, as the people who read it propose papers they would like to read! Think [*Pinterest*](http://pinterest.com/) instead of editorial manager.

A journal engaging in such practice would not seem parasitic to me: if people are volunteering time to review and improve great papers, it's too bad to start the process from scratch every time you change journal. Some people argued for [the recycling of reviews](http://www.ncbi.nlm.nih.gov/pubmed/22341497), and I think they are entirely right — not nearly enough journals are accepting review transfer in my opinion, further cluttering the system, and giving you the impression to start the fight over at each submission to a new journal. Gathering already reviewed papers would essentially push this logic to the maximum. It's time we review a paper for the science inside, not for the journal it will end up in; perhaps I'm being naive, but it appears to me that this is an editorial decision, on which the reviewers should have a limited impact.

# Be social and engage

I've ranted long enough already, so it's time to bring this essay to its term. The final point is of course, *be open*. I've already called for more [communication](http://timotheepoisot.fr/2011/11/19/get-your-lab-on-twitter/) and [diffusion of your code](http://timotheepoisot.fr/2012/01/06/science-age-social-coding/). I think that engaging with the community of authors, readers, and referees is important. *Methods in Ecology and Evolution* is [doing a great job](http://methodsblog.wordpress.com/2012/04/04/omgwhathaveidone/) in this regard. More and more people are know able to navigate social networks quite well, and there is no reason for journals not to do it. And if possible, to do it genuinely, i.e. by actually engaging with the authors and the readership, like the folks running the [Oikos blog are doing when they ask authors to discuss recently accepted papers](http://oikosjournal.wordpress.com/2012/04/16/why-shoot-yourself-in-the-foot/). Tweeting the title of your recently accepted articles is definitely a first step, but it's by no mean sufficient to be considered an engagement with the people reading your journal.

# Be open

And of course, this journal should be open-access.	 Using a platform like [Scholastica](http://innge.net/?q=node%2F327) would help in this regard: it's easy to create an on-line only, open access journal, for a minimal cost (both for the authors and the publishers). But open-access goes well beyond the text. Use [FigShare](http://figshare.com/), [TreeBase](http://www.treebase.org/treebase-web/home.html) and [DataDryad](http://datadryad.org/), and make sure the research you publish is open to all, and easily reproducible. It might be frightening to part with your data, but I'm sure it will help the paper get cited in the long run; people will be able to reproduce what you do, the quality of meta-analyses will increase. And in addition, it will put an end to an hideous behavior: I'll give you my data from 15 years ago, if you put me as a co-author, me and all my chums. The challenge of ecology is probably not to deal with extremely large datasets — though my opinion on this point changed slightly since I've had to deal with pyrosequencing data —, but to integrate a lot of small datasets to answer the big questions. We probably would have enough data to do a good decade of science, it said data were easy to access, and not sitting on the hard drive of hundreds of researchers around the world. Data sharing will also be encouraged if people have the opportunity to submit their manuscript in a way allowing reproducible research, i.e. using tools suchs as [`knitr`](http://yihui.name/knitr/) or [`Sweave`](http://en.wikipedia.org/wiki/Sweave).

Finally, while an Open Access licence seems straigthforward, it begs the question of how to get the money to cover the publication fees — I'm personally opposed to excessive OA charges, so preferably the journal shoudl function with a very small funding. My impression is that, by using the services mentionned above, there will be very little costs associated with the journal maintenance. Being supported by a society will definitely be a plus, as it might probably help to have one person in charge of the administrative tasks. The most important cost will probably be web hosting, and I'm confident that it can be kickstarted by applying to fund-gathering projects in [PetriDish](http://www.petridish.org/) or [SciFund](http://scifundchallenge.org/). Crowd-sourcing and crowd-funding, together at last!

# Fight centralization

In summary, what I propose amounts to the crowd-sourcing of most of the tasks related to the publishing process. I was pleased that, during the time where I was writing this piece, there was a call for [ideas about the creation of a new journal on *EvolDir*](http://life.biology.mcmaster.ca/~brian/evoldir/Other/Journal.Society.Coevolution) (I was also pleased that this journal, if it happens, will cover coevolution). The people behind this idea were actively asking other researchers for their input, because the «crowd» will be refereeing, submitting, and reading the papers.

I think there is much to be gained by adopting an idealistic point of view about what a journal can be now that a lot of great people have thought about new ways to do science in the electronic, open-access, next-gen era. Not only will it be fun to see what happen, it may even end up being a viable alternative to journals who inherited their publishing process from a hundred years ago.