<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title>Tim Poisot :: Updates</title>
  <link href="http://timotheepoisot.fr/atom.xml" rel="self"/>
  <link href="http://timotheepoisot.fr/"/>
  <updated>2014-01-20T12:18:01-05:00</updated>
  <id>Tim Poisot</id>
  <author>
    <name>Tim Poisot</name>
    <email></email>
  </author>
  
  <entry>
     <title>Semantic versioning for scientific software</title>
     <link href="http://timotheepoisot.fr/2014/01/20/semantic-versioning/"/>
    <updated>2014-01-20T00:00:00-05:00</updated>
    <content type="html">&lt;p&gt;I have recently discovered the concept of &lt;a href=&quot;http://semver.org/&quot;&gt;semantic versioning&lt;/a&gt;,
introduced by Tom Preston-Werner. In short, semantic versioning is a
way to know whether two versions of a program will behave in the same
way. A program conforming to this specification has a version number of
&lt;code&gt;major&lt;/code&gt;.&lt;code&gt;minor&lt;/code&gt;.&lt;code&gt;patch&lt;/code&gt;, and comparing two version numbers will tell you
exactly what to expect in terms of compatibility. Versions with different
&lt;code&gt;major&lt;/code&gt; numbers are not supposed to be compatible. A version with a higher
&lt;code&gt;minor&lt;/code&gt; number will have additional, backwards compatible functions. Different
levels of &lt;code&gt;patch&lt;/code&gt; will correspond to issues solving and so forth.&lt;/p&gt;

&lt;p&gt;Semantic versioning is intended for programs declaring a public API, as
all &lt;code&gt;R&lt;/code&gt; packages do (the various functions and data formats). Any package,
module, etc., declaring functions that will be used in user-written scripts
are within the scope of semantic versioning. A script that you wrote using
v. &lt;code&gt;1.2.3&lt;/code&gt; will work when &lt;code&gt;1.3.1&lt;/code&gt; or &lt;code&gt;1.2.4&lt;/code&gt; are released, but &lt;em&gt;not&lt;/em&gt; when
&lt;code&gt;2.0.0&lt;/code&gt; is. An important point is that, unless &lt;code&gt;major&lt;/code&gt; is &lt;code&gt;1&lt;/code&gt;, the software
is considered unstable: the API can change very rapidly, and so it should
not be used for production.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://yihui.name/en/2013/06/r-package-versioning/&quot;&gt;Yihui Xie&lt;/a&gt; proposes a slightly different set of rules, specifically
aimed at &lt;code&gt;R&lt;/code&gt; packages. When the &lt;code&gt;minor&lt;/code&gt; version increases, release the new
version of your package to &lt;code&gt;CRAN&lt;/code&gt; (as &lt;code&gt;patch&lt;/code&gt; versions are not supposed to
introduce new features anyway). People can just save time by referring to the
&lt;code&gt;major&lt;/code&gt;.&lt;code&gt;minor&lt;/code&gt; version of the package. The way semantic versioning works,
you will only submit &lt;code&gt;major&lt;/code&gt;.&lt;code&gt;minor&lt;/code&gt;.&lt;code&gt;0&lt;/code&gt; versions to &lt;code&gt;CRAN&lt;/code&gt; (because each
time a number increases, all numbers to the right are set to &lt;code&gt;0&lt;/code&gt;). And so
any version with &lt;code&gt;patch&lt;/code&gt; higher than &lt;code&gt;0&lt;/code&gt; is a &lt;em&gt;development&lt;/em&gt; version.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;What is the relevance of that for people not contributing to software
development? I think using semantic versioning is useful if we &lt;em&gt;report&lt;/em&gt;
version numbers in the papers in the same way. If you distribute supplementary
files with your paper, such as &lt;code&gt;R&lt;/code&gt; scripts, don’t give the package name,
but also the version of the package you used. This can be viewed using
&lt;code&gt;sessionInfo()&lt;/code&gt;. If you use package &lt;code&gt;foo&lt;/code&gt;, v. &lt;code&gt;1.3.0&lt;/code&gt;, and the maintainer of
package &lt;code&gt;foo&lt;/code&gt; uses semantic versioning, if someone tries to use your script
a few years later with &lt;code&gt;foo&lt;/code&gt; v. &lt;code&gt;2.1.0&lt;/code&gt;, it is &lt;em&gt;possible&lt;/em&gt; that things will
break. If you clearly state which packages versions are used, it will be easier
for users to install the correct version of the packages to run your analyses.&lt;/p&gt;

&lt;p&gt;Correct reporting of software versions is important (and I’ve been guilty of
not using top-notch practices myself), but if an increasing number of people
start using semantic versioning, it will &lt;em&gt;help&lt;/em&gt; re-use of code. In short,
we should always give the full version number when mentioning a package
or software.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;As a final note, this also require the those of us producing code adopt
better development practices. In &lt;em&gt;GitHub&lt;/em&gt;, it is easy to tag releases,
so that all different versions are available over time. And because the
ultimate goal of semantic versioning is to ensure backwards compatibility,
we need to be sure that new fixes or additions do not break it. This can
be done by writing thorough test suites. Unless a new addition results in
previously passing tests failing, it can be considered safe.&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>Python wrapper for mangal</title>
     <link href="http://timotheepoisot.fr/2014/01/19/pymangal/"/>
    <updated>2014-01-19T00:00:00-05:00</updated>
    <content type="html">&lt;p&gt;I use &lt;code&gt;python&lt;/code&gt; more than I use &lt;code&gt;R&lt;/code&gt; for my own job. &lt;code&gt;R&lt;/code&gt; is good to share
things with people, but it’s a little bit slower, and orders of magnitude
quirkier, than &lt;code&gt;python&lt;/code&gt;. So I decided to write a &lt;code&gt;python&lt;/code&gt; wrapper for the
&lt;code&gt;mangal&lt;/code&gt; API, which you can &lt;a href=&quot;https://github.com/mangal-wg/pymangal&quot;&gt;find on &lt;em&gt;GitHub&lt;/em&gt;&lt;/a&gt;. It works with
&lt;code&gt;python&lt;/code&gt; 2.6 and 2.7 (at least the test suite passes on these two versions).&lt;/p&gt;

&lt;p&gt;The goal is &lt;em&gt;not&lt;/em&gt; to release something as full-featured as the &lt;code&gt;rmangal&lt;/code&gt;
package (though the core abilities will be here). Rather, I wanted a tool that
is “pythonic”, easy to use, and programmed extremely defensively so that it
can be used for automated analyses. There is a minimal &lt;a href=&quot;http://pymangal.readthedocs.org/en/latest/&quot;&gt;documentation&lt;/a&gt;
online, which will hopefully get better over time as I understand the
&lt;code&gt;sphinx&lt;/code&gt; markup.&lt;/p&gt;

&lt;p&gt;The syntax is relatively similar to that of the &lt;code&gt;rmangal&lt;/code&gt; package. Everything starts by the instansiation of a &lt;code&gt;mangal()&lt;/code&gt; class.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;&amp;gt;&amp;gt;&amp;gt; import pymangal as pm
&amp;gt;&amp;gt;&amp;gt; api = pm.mangal(url=&#39;http://localhost:8000&#39;)
&amp;gt;&amp;gt;&amp;gt; api.resources
[u&#39;interaction&#39;, u&#39;network&#39;, u&#39;reference&#39;, u&#39;taxa&#39;, u&#39;trait&#39;, u&#39;dataset&#39;, u&#39;environment&#39;, u&#39;item&#39;, u&#39;user&#39;, u&#39;population&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The methods implemented by the &lt;code&gt;mangal&lt;/code&gt; class are &lt;code&gt;List&lt;/code&gt;, &lt;code&gt;Get&lt;/code&gt;, and &lt;code&gt;Post&lt;/code&gt;
(&lt;code&gt;Patch&lt;/code&gt; is coming soon, and &lt;code&gt;Post&lt;/code&gt; support is sketchy at best). They work
almost in the same way as their &lt;code&gt;R&lt;/code&gt; counterparts. For example, getting a
list of all networks can be done with:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;&amp;gt;&amp;gt;&amp;gt; all_net = api.List(&#39;network&#39;)
&amp;gt;&amp;gt;&amp;gt; len(all_net)
17
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The only significant difference is that, by default, the &lt;code&gt;python&lt;/code&gt; version will only return the first 20 results. If you want more than 20  results, you need to use &lt;code&gt;autopage=True&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;&amp;gt;&amp;gt;&amp;gt; twenty_taxa = api.List(&#39;taxa&#39;)
&amp;gt;&amp;gt;&amp;gt; len(twenty_taxa)
20
&amp;gt;&amp;gt;&amp;gt; all_taxa = api.List(&#39;taxa&#39;, autopage=True)
&amp;gt;&amp;gt;&amp;gt; len(all_taxa)
38
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;em&gt;big&lt;/em&gt; advantage of the &lt;code&gt;python&lt;/code&gt; version is that, when uploading data, there
is a validation of the way they are formatted. Internally, there is a function
taking care of reading the API scheme, and returning it as a &lt;code&gt;json&lt;/code&gt; schema,
against which data are checked. It’s probably simpler with a demonstration…&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;&amp;gt;&amp;gt;&amp;gt; print json.dumps(api.schemes[&#39;trait&#39;], indent=2)
## I have cut some of the elements for the sake of brevity
{
   &quot;$schema&quot;: &quot;http://json-schema.org/draft-04/schema#&quot;, 
   &quot;required&quot;: [
      &quot;value&quot;, 
      &quot;owner&quot;, 
      &quot;name&quot;
   ], 
   &quot;type&quot;: &quot;object&quot;, 
   &quot;properties&quot;: {
      &quot;name&quot;: {
         &quot;type&quot;: &quot;string&quot;, 
         &quot;description&quot;: &quot;The name of the measured trait&quot;
      }, 
      &quot;value&quot;: {
         &quot;type&quot;: &quot;string&quot;, 
         &quot;description&quot;: &quot;The value of the trait&quot;
      }, 
      &quot;units&quot;: {
         &quot;type&quot;: &quot;string&quot;, 
         &quot;description&quot;: &quot;Units in which the trait was measured&quot;
      }
   }, 
   &quot;title&quot;: &quot;Autogenerated JSON schema&quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The data are validated &lt;em&gt;automatically&lt;/em&gt;, so you don’t have to bother about checking them yourself. For example, let’s try with a badly formatted, and with a correctly formatted, taxa &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;&amp;gt;&amp;gt;&amp;gt; bad_taxa = {&#39;name&#39;: &#39;Vulpes lagopus&#39;, &#39;vernacular&#39;: &#39;arctic fox&#39;, &#39;eol&#39;: 1053894, &#39;status&#39;: &#39;valid&#39;}
# &quot;valid&quot; is not an acceptable value for &quot;status&quot; (&quot;confirmed&quot; is)
&amp;gt;&amp;gt;&amp;gt; ok_taxa = {&#39;name&#39;: &#39;Vulpes lagopus&#39;, &#39;vernacular&#39;: &#39;arctic fox&#39;, &#39;eol&#39;: 1053894, &#39;status&#39;: &#39;confirmed&#39;}

&amp;gt;&amp;gt;&amp;gt; arctic_fox = 
&amp;gt;&amp;gt;&amp;gt; arctic_fox = api.Post(&#39;taxa&#39;, bad_taxa)
# Skipping some lines...
jsonschema.exceptions.ValidationError: &#39;valid&#39; is not one of [u&#39;confirmed&#39;, u&#39;trophic species&#39;, u&#39;morphospecies&#39;, u&#39;nomen dubium&#39;, u&#39;nomen oblitum&#39;, u&#39;nomen nudum&#39;, u&#39;nomen novum&#39;, u&#39;nomen conservandum&#39;, u&#39;species inquirenda&#39;]

Failed validating &#39;enum&#39; in schema[&#39;properties&#39;][u&#39;status&#39;]:
{&#39;description&#39;: u&#39;The taxonomic status of the taxa.&#39;,
   &#39;enum&#39;: [u&#39;confirmed&#39;,
   u&#39;trophic species&#39;,
   u&#39;morphospecies&#39;,
   u&#39;nomen dubium&#39;,
   u&#39;nomen oblitum&#39;,
   u&#39;nomen nudum&#39;,
   u&#39;nomen novum&#39;,
   u&#39;nomen conservandum&#39;,
   u&#39;species inquirenda&#39;],
&#39;type&#39;: u&#39;string&#39;}

On instance[u&#39;status&#39;]:
&#39;valid&#39;

&amp;gt;&amp;gt;&amp;gt; arctic_fox = api.Post(&#39;taxa&#39;, ok_taxa)
&amp;gt;&amp;gt;&amp;gt; arctic_fox[&#39;id&#39;]
103
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that the &lt;code&gt;validate&lt;/code&gt; function of the &lt;code&gt;jsonschema&lt;/code&gt; will tell you what is
wrong with the data, and show you the relevant excerpt from the schema. This
really helps finding out what it wrong with the data you try to upload.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;As a final note: I am using &lt;em&gt;&lt;a href=&quot;https://coveralls.io/r/mangal-wg/pymangal&quot;&gt;Coveralls.io&lt;/a&gt;&lt;/em&gt; for the first time,
and I am extremely impressed. In short, &lt;em&gt;coveralls&lt;/em&gt; will read the results
of the &lt;code&gt;coverage&lt;/code&gt; command, and tell you the proportion of your code with
corresponding test cases. &lt;em&gt;Coveralls&lt;/em&gt; is integrated with &lt;em&gt;TravisCI&lt;/em&gt;, a
continuous integration engine runnign the test suite each time I commit
changes to the &lt;em&gt;GitHub&lt;/em&gt; repository (so I have confirmation that the new
versions pass  the tests). And finally, the documentation is auto-generated
using &lt;em&gt;Read The Docs&lt;/em&gt;, which extracts the informations directly from the
code. These are really impressive tools to work with, and they kind of force
good practices upon you – which is a good thing.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;As usual, posting and patching requires that you have a username and password. There will be a way to register through the &lt;code&gt;python&lt;/code&gt; package in the future.&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</content>
  </entry>
  
  <entry>
     <title>These aren't the networks you're looking for</title>
     <link href="http://timotheepoisot.fr/2014/01/14/filtering-in-mangal/"/>
    <updated>2014-01-14T00:00:00-05:00</updated>
    <content type="html">&lt;p&gt;The development of the &lt;code&gt;rmangal&lt;/code&gt; package is making good progress. I just
finised implementing a way to filter results, which will be extremely useful
when the number of taxa and networks will start growing. Before we get into
how filtering is done, I’d like to take the opportunity to bore everyone
with technical details. &lt;code&gt;mangal&lt;/code&gt; (the API) relies on &lt;code&gt;tastypie&lt;/code&gt;, which is a
&lt;code&gt;django&lt;/code&gt; plugin to use the data models as API resources (bored yet?). The
&lt;code&gt;tastypie&lt;/code&gt; developers had the good taste to allow &lt;code&gt;django&lt;/code&gt;’s ORM filter as
URL parameters to filter results. Or in short, there is a filtering solution
working out of the box.&lt;/p&gt;

&lt;p&gt;The filtering is realtively easy to do, as it follows the common pattern:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;?field__relation=target
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For example, to look for taxa whose name starts with &lt;em&gt;Lamellodiscus&lt;/em&gt;, we
just need to append:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;?name__startswith=Lamellodiscus
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&quot;the-basics-of-filtering&quot;&gt;The basics of filtering&lt;/h1&gt;

&lt;p&gt;So how does it works in the &lt;code&gt;R&lt;/code&gt; package? There is a &lt;code&gt;mangalSearch&lt;/code&gt; function,
which takes as arguments the &lt;code&gt;api&lt;/code&gt;, the type of resource to look for (the
list of resources can be now be viewed with &lt;code&gt;api$resources&lt;/code&gt;), and a list of
filters. The filters are themselves &lt;code&gt;list&lt;/code&gt; objects, with three properties:
&lt;code&gt;field&lt;/code&gt;, &lt;code&gt;relation&lt;/code&gt; (I give an overview of these below), and &lt;code&gt;target&lt;/code&gt;. Let
me illustrate:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(rmangal)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Loading required package: rjson
## Loading required package: httr
## Loading required package: igraph
## Loading required package: stringr
## Loading required package: cheddar
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;api &amp;lt;- mangalapi(&quot;http://localhost:8000/&quot;)
Amphiprion &amp;lt;- mangalSearch(api, &quot;taxa&quot;, list(list(field = &quot;name&quot;, relation = &quot;startswith&quot;, 
    target = &quot;Amphiprion&quot;)))
laply(Amphiprion, function(x) x$name)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &quot;Amphiprion clarkii&quot;      &quot;Amphiprion perideraion&quot; 
## [3] &quot;Amphiprion ocellaris&quot;    &quot;Amphiprion sandaracinos&quot;
## [5] &quot;Amphiprion melanopus&quot;    &quot;Amphiprion polymnus&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It may look like a convoluted way to do a simple thing, &lt;em&gt;but&lt;/em&gt; the interest
is that you can combine filters to have more precise requests. Let’s say we
are really interested in a small portion of the pacific ocean, and want to
know if there are any networks inside. We will define two different filters:
one for latitude, and one for longitude.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;filter_lat = list(field = &quot;latitude&quot;, relation = &quot;range&quot;, target = c(1.756, 
    1.813))
filter_lon = list(field = &quot;longitude&quot;, relation = &quot;range&quot;, target = c(124.76, 
    124.808))
Networks &amp;lt;- mangalSearch(api, &quot;network&quot;, list(filter_lat, filter_lon))
laply(Networks, function(x) x$name)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &quot;Batu Kapal&quot;  &quot;Jalan Masuk&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&quot;types-of-relations&quot;&gt;Types of relations&lt;/h1&gt;

&lt;p&gt;There are ten different values for the &lt;code&gt;relation&lt;/code&gt; type. &lt;code&gt;starswith&lt;/code&gt; and
&lt;code&gt;endswith&lt;/code&gt; will match the beginnign and end of the value. &lt;code&gt;exact&lt;/code&gt; will match
the entirety of the field. &lt;code&gt;contains&lt;/code&gt; will look for &lt;code&gt;target&lt;/code&gt; somewhere in
the field. &lt;code&gt;in&lt;/code&gt; will return objects that have &lt;code&gt;target&lt;/code&gt; in the values of a
multi-valued field (example of use: with the identifier of an interactio,
find the network it belongs to). &lt;code&gt;range&lt;/code&gt; will return all objects that have
values in the &lt;code&gt;target&lt;/code&gt; range. And finally, &lt;code&gt;gte&lt;/code&gt;, &lt;code&gt;gt&lt;/code&gt;, &lt;code&gt;lte&lt;/code&gt; and &lt;code&gt;lt&lt;/code&gt;,
handle superior/inferior (or equal) relationships.&lt;/p&gt;

&lt;h1 id=&quot;more-advanced-usage&quot;&gt;More advanced usage&lt;/h1&gt;

&lt;p&gt;If you look at the code of &lt;code&gt;mangalSearch&lt;/code&gt;, you’ll see that it passes
an addition argument (&lt;code&gt;filtering&lt;/code&gt;) to &lt;code&gt;mangalList&lt;/code&gt;. This allows you
to handle more complicated filtering schemes. In the filtering pattern
&lt;code&gt;field__relation=target&lt;/code&gt;, &lt;code&gt;field&lt;/code&gt; can actually be a &lt;em&gt;path&lt;/em&gt; across multiple
objects. Let’s illustrate with an example.&lt;/p&gt;

&lt;p&gt;We want to retrieve all interactions involving &lt;code&gt;taxa&lt;/code&gt; whose name starts with
&lt;code&gt;Amphiprion&lt;/code&gt;. The &lt;em&gt;path&lt;/em&gt; from &lt;code&gt;interaction&lt;/code&gt; to &lt;code&gt;taxa&lt;/code&gt; goes through the field &lt;code&gt;taxa_to&lt;/code&gt;/&lt;code&gt;taxa_from&lt;/code&gt; in interaction. So what we want to do is:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;?taxa_from__name__startswith=Amphiprion
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can add that as the &lt;code&gt;filtering&lt;/code&gt; argument of &lt;code&gt;mangalList&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;Interactions &amp;lt;- rmangal:::mangalList(api, &quot;interaction&quot;, filtering = &quot;taxa_from__name__startswith=Amphiprion&quot;)
laply(Interactions, function(x) x$id)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] &quot;93&quot;  &quot;92&quot;  &quot;87&quot;  &quot;86&quot;  &quot;85&quot;  &quot;82&quot;  &quot;81&quot;  &quot;76&quot;  &quot;75&quot;  &quot;69&quot;  &quot;68&quot; 
## [12] &quot;67&quot;  &quot;59&quot;  &quot;58&quot;  &quot;53&quot;  &quot;52&quot;  &quot;51&quot;  &quot;50&quot;  &quot;45&quot;  &quot;44&quot;  &quot;23&quot;  &quot;24&quot; 
## [23] &quot;25&quot;  &quot;26&quot;  &quot;27&quot;  &quot;28&quot;  &quot;29&quot;  &quot;30&quot;  &quot;31&quot;  &quot;32&quot;  &quot;33&quot;  &quot;34&quot;  &quot;35&quot; 
## [34] &quot;36&quot;  &quot;37&quot;  &quot;38&quot;  &quot;39&quot;  &quot;41&quot;  &quot;42&quot;  &quot;43&quot;  &quot;44&quot;  &quot;45&quot;  &quot;46&quot;  &quot;47&quot; 
## [45] &quot;48&quot;  &quot;49&quot;  &quot;50&quot;  &quot;51&quot;  &quot;52&quot;  &quot;53&quot;  &quot;54&quot;  &quot;56&quot;  &quot;58&quot;  &quot;59&quot;  &quot;60&quot; 
## [56] &quot;61&quot;  &quot;62&quot;  &quot;64&quot;  &quot;65&quot;  &quot;66&quot;  &quot;67&quot;  &quot;68&quot;  &quot;69&quot;  &quot;71&quot;  &quot;72&quot;  &quot;73&quot; 
## [67] &quot;75&quot;  &quot;76&quot;  &quot;77&quot;  &quot;78&quot;  &quot;79&quot;  &quot;81&quot;  &quot;82&quot;  &quot;83&quot;  &quot;84&quot;  &quot;85&quot;  &quot;86&quot; 
## [78] &quot;87&quot;  &quot;88&quot;  &quot;89&quot;  &quot;90&quot;  &quot;91&quot;  &quot;92&quot;  &quot;93&quot;  &quot;95&quot;  &quot;96&quot;  &quot;97&quot;  &quot;98&quot; 
## [89] &quot;99&quot;  &quot;100&quot; &quot;101&quot; &quot;102&quot; &quot;103&quot; &quot;104&quot; &quot;105&quot; &quot;106&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Because &lt;code&gt;mangalList&lt;/code&gt; is not exported, you have to use the &lt;code&gt;:::&lt;/code&gt; operator
to explicitely call it. Note that these functions may not work (quite yet)
with the public database, because we will update the API later this week.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
     <title>Animate networks with igraph</title>
     <link href="http://timotheepoisot.fr/2014/01/11/animate-networks-with-igraph/"/>
    <updated>2014-01-11T00:00:00-05:00</updated>
    <content type="html">&lt;p&gt;The &lt;code&gt;igraph&lt;/code&gt; package in &lt;code&gt;R&lt;/code&gt; is a good solution to manipulate networks. A
few days ago, I had to produce an animated figure for a paper, and I really
wanted to use &lt;code&gt;igraph&lt;/code&gt; to do it. As it turns out, it’s not overly complicated
(you need to have &lt;code&gt;imagemagick&lt;/code&gt; installed, though.&lt;/p&gt;

&lt;p&gt;So as to provide a quick visualisation, let’s start with a simple dynamical
model of a diamond food web (one primary producer, two consumers, one top
predator, classic stuff). The “usual” way to represent the dynamics of biomass
is to have four time series. The “captivating” way (good for talks!) is to
animate the network, with each node size being proportional to its biomass
at any time.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(igraph)
library(simecol)

# A simple LV diamond food web model
glv &amp;lt;- function(time, init, parms) {
    N &amp;lt;- init
    with(as.list(parms), {
        d1 = N[1] * (rp - (a1p * N[2] + a2p * N[3]))
        d2 = N[2] * (rc + a1p * N[1] - ap1 * N[4])
        d3 = N[3] * (rc + a2p * N[1] - ap2 * N[4])
        d4 = N[4] * (rt + ap1 * N[3] + ap1 * N[2])
        return(list(c(d1, d2, d3, d4)))
    })
}

# Some default parameters
params &amp;lt;- c(rp = 1.1, rc = -0.2, rt = -0.6, a1p = 0.8, a2p = 0.4, ap1 = 0.21, 
    ap2 = 0.12)
init &amp;lt;- c(10, 4, 3, 5)
times &amp;lt;- seq(from = 0, to = 50, length = 300)

# And the simulations...
output &amp;lt;- ode(init, times, func = glv, parms = params)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nevermind that the parameters aren’t realistic at all, it’s not what matters
for this example. At this point, we have a simulation running for 50 timesteps,
with a total of 300 points. Now, let’s build a graph:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;adjacency &amp;lt;- matrix(c(0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0), 4, 4)
diamond &amp;lt;- graph.adjacency(adjacency)
layout &amp;lt;- layout.fruchterman.reingold(diamond)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can start building a loop to create all networks for each time. The trick is
that &lt;code&gt;igraph&lt;/code&gt; accepts vectors for allmost all edges and vertex attributes. It
can be used to change the color, size, label, etc. An important point is that,
by default, the layout of each plot is scaled and center. But in our case,
it’s important that it’s fixed for all plots, so we’ll just need to add
&lt;code&gt;rescale = FALSE&lt;/code&gt;, and give explicit &lt;code&gt;xlim&lt;/code&gt; and &lt;code&gt;ylim&lt;/code&gt;; this way, the center
of each vertex is always at the same position.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;# We&#39;ll make sure that the maximal biomass is not too big
MaxBio &amp;lt;- max(output[, -1])
png(file = &quot;biomass_%04d.png&quot;, width = 300, height = 300)

for (i in c(1:nrow(output))) {
    Biomass &amp;lt;- output[i, -1]
    plot(diamond, layout = layout, vertex.size = 10 * Biomass, rescale = FALSE, 
        xlim = range(layout[, 1]), ylim = range(layout[, 2]))
}
dev.off()

# The we use ImageMagick to convert all images to a gif file
system(&quot;convert -delay 5 biomass_*.png animation_biomass.gif&quot;)
# And remove the images
file.remove(list.files(pattern = &quot;biomass_&quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And here is the result:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/rfig/animation_biomass.gif&quot; alt=&quot;Animation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Clearly it’s not extremely good looking, but it can help show the dynamics
of networks. An interesting thing is that you can also &lt;em&gt;hide&lt;/em&gt; some edges or
vertices, so it’s possible to show temporal dynamics.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
     <title>Examples of mangal in action</title>
     <link href="http://timotheepoisot.fr/2014/01/09/mangal-in-action/"/>
    <updated>2014-01-09T00:00:00-05:00</updated>
    <content type="html">&lt;p&gt;In the two previous posts (see &lt;a href=&quot;http://timotheepoisot.fr/2014/01/07/mangal-database-networks/&quot;&gt;Part 1&lt;/a&gt; and &lt;a href=&quot;http://timotheepoisot.fr/2014/01/08/mangal-add-data/&quot;&gt;Part 2&lt;/a&gt;), I’ve presented the basics of using &lt;code&gt;mangal&lt;/code&gt; and the &lt;code&gt;rmangal&lt;/code&gt; package to access, deposit, and edit data about ecological networks. The final post in the series is going to be slightly more fun: I’ll illustrate some use cases of things you can potentially do with the database. We will start from the representation of a network in space, then move on to measuring beta-diversity in the dataset, and end with some more classical species-links relationships.&lt;/p&gt;

&lt;h1 id=&quot;setting-things-up&quot;&gt;Setting things up&lt;/h1&gt;

&lt;p&gt;We’ll need to pull the latest version of &lt;code&gt;rmangal&lt;/code&gt;, as usual. In addition, we’ll need a few other packages.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;options(stringsAsFactors = FALSE)
if (getOption(&quot;unzip&quot;) == &quot;&quot;) options(unzip = &quot;unzip&quot;)
library(devtools)
install_github(&quot;rmangal&quot;, &quot;mangal-wg&quot;)
install_github(&quot;betalink&quot;, &quot;tpoisot&quot;)
library(rmangal)
# Let&#39;s connect to the database
URL &amp;lt;- &quot;http://localhost:8000&quot;
api &amp;lt;- rmangal::mangalapi(URL)
library(betalink)
# Tools for spatial analyses
library(sp)
library(RgoogleMaps)
library(RColorBrewer)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;span class=&quot;margin&quot;&gt;Ricciardi et al. (2010) &lt;em&gt;Env Biol Fishes&lt;/em&gt; &lt;a href=&quot;http://dx.doi.org/10.1007/s10641-010-9606-0&quot;&gt;DOI&lt;/a&gt;&lt;/span&gt;I will do everything using a dataset released by Ricciardi and colleagues. The &lt;a href=&quot;http://www.nceas.ucsb.edu/interactionweb/html/ricciardi-et-al-2010.html&quot;&gt;original data&lt;/a&gt; are on the &lt;em&gt;Interaction Web DataBase&lt;/em&gt;. This dataset describes 16 anemonefish/fishes mutualistic networks in Indonesia. It’s an extremely cool dataset, because (i) there are a lot of sites in a small space, (ii) a lot of species are in common across sites, and (iii) anemonefishes. So I’ve uploaded these data in my local copy of the database, and I’m going to illustrate a few uses-cases. The only “manual” operation was determining the spatial coordinates in each networks, based on the map presented in the original paper.&lt;/p&gt;

&lt;h1 id=&quot;use-case-1-spatialized-network&quot;&gt;Use-case 1: spatialized network&lt;/h1&gt;

&lt;p&gt;&lt;span class=&quot;margin&quot;&gt;Bascompte (2009) &lt;em&gt;Science&lt;/em&gt; &lt;a href=&quot;http://dx.doi.org/10.1126/science.1170749&quot;&gt;DOI&lt;/a&gt;&lt;/span&gt;There is a really cool figure in one of Jordi Bascompte’s paper, in which a network is plotted in space, and the position of each species is the center of mass of its area. This is an interesting way to plot networks when spatial information is available, so let’s do just that.&lt;/p&gt;

&lt;p&gt;We start by getting the dataset:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;Dataset &amp;lt;- getDataset(api, 8)
Dataset$networks
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] &quot;32&quot; &quot;33&quot; &quot;18&quot; &quot;19&quot; &quot;20&quot; &quot;21&quot; &quot;22&quot; &quot;23&quot; &quot;24&quot; &quot;25&quot; &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot;
## [15] &quot;30&quot; &quot;31&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, this dataset has a lot of networks. So we’ll do to things. First, we will get a list of all network objects, because they have the metadata we need:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;Networks &amp;lt;- alply(Dataset$networks, 1, function(x) getNetwork(api, x))
Networks[[1]]$latitude
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 1.651
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, we will call the &lt;code&gt;network_as_graph&lt;/code&gt; function to get all the interactions, and associated informations on the taxa. We will also convert these graphs into matrices, because that will be easier for some of the next steps.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;Graphs &amp;lt;- llply(Networks, function(x) network_as_graph(api, x$id))
names(Graphs) &amp;lt;- laply(Networks, function(x) x$name)
Matrices &amp;lt;- llply(Graphs, get.adjacency, sparse = FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let’s now get a table with the sites spatial coordinates:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;Coord &amp;lt;- ldply(Networks, function(x) c(name = x$name, lon = x$longitude, lat = x$latitude))
rownames(Coord) &amp;lt;- Coord$name
Coord &amp;lt;- Coord[, c(&quot;lat&quot;, &quot;lon&quot;)]
Coord$lat &amp;lt;- as.numeric(Coord$lat)
Coord$lon &amp;lt;- as.numeric(Coord$lon)
head(Coord)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##                 lat   lon
## Tanjung Kopi  1.651 124.7
## Tanjung Pisok 1.578 124.8
## bahowo        1.585 124.8
## Kampung Bajo  1.608 124.9
## Batu Kapal    1.788 124.8
## Bualo         1.616 124.7
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Good!&lt;/p&gt;

&lt;p&gt;Almost final steps, let’s (i) get the list of species in each site, (ii) make a community matrix from this, and (iii) calculate the center of mass of each species based on its occurence in each of the 16 locations. &lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;# Get the list of species
sp_by_site &amp;lt;- llply(Graphs, function(x) unlist(V(x)$name))
sp_list &amp;lt;- unique(unlist(sp_by_site))

# Species-by-site matrix
M &amp;lt;- matrix(0, ncol = length(sp_list), nrow = length(sp_by_site))
colnames(M) &amp;lt;- sp_list
rownames(M) &amp;lt;- names(sp_by_site)
for (site in c(1:length(sp_by_site))) M[names(sp_by_site)[site], sp_by_site[[site]]] = 1

# Get the center of mass for each species
sp_center &amp;lt;- adply(M, 2, function(x) colMeans(Coord[names(x)[x &amp;gt; 0], ]))
rownames(sp_center) &amp;lt;- sp_center[, 1]
sp_center &amp;lt;- sp_center[, -1]
head(sp_center)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##                           lat   lon
## Entacmaea quadricolor   1.599 124.8
## Heteractis aurora       1.677 124.8
## Heteractis crispa       1.614 124.8
## Stichodactyla mertensii 1.625 124.8
## Heteractis magnifica    1.601 124.8
## Amphiprion melanopus    1.620 124.7
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, we use the &lt;code&gt;metaweb&lt;/code&gt; function from &lt;code&gt;betalink&lt;/code&gt; to get the regional network, as an &lt;code&gt;igraph&lt;/code&gt; graph:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;Mw &amp;lt;- graph.adjacency(metaweb(Matrices)$web)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And now, we’ll use the &lt;code&gt;RgoogleMaps&lt;/code&gt; package to plot a map, and overlay the spatialized network on top:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;# But first we need this function to convert spatial coordinates
ll_to_gm &amp;lt;- function(Map, ll) {
    # Lat. conversion
    lat &amp;lt;- ll$lat
    lat &amp;lt;- lat - Map$lat.center
    lat &amp;lt;- lat/(Map$BBOX$ur[, &quot;lat&quot;] - Map$BBOX$ll[, &quot;lat&quot;])
    lat &amp;lt;- lat * 640
    # Lat. conversion
    lon &amp;lt;- ll$lon
    lon &amp;lt;- lon - Map$lon.center
    lon &amp;lt;- lon/(Map$BBOX$ur[, &quot;lon&quot;] - Map$BBOX$ll[, &quot;lon&quot;])
    lon &amp;lt;- lon * 640
    ## Return matrix
    return(cbind(lon, lat))
}
# Plot a map
center_point &amp;lt;- colMeans(sp_center)
Map &amp;lt;- GetMap(center = center_point, zoom = 11, SCALE = 1)
par(pty = &quot;s&quot;)
colors &amp;lt;- c(brewer.pal(9, &quot;Set1&quot;), brewer.pal(8, &quot;Set2&quot;))
PlotOnStaticMap(Map)
plot(Mw, layout = jitter(ll_to_gm(Map, sp_center), amount = 10), rescale = FALSE, 
    add = TRUE, vertex.size = 600, vertex.label = NA, vertex.color = colors, 
    edge.arrow.size = 0.25, edge.color = 1)
legend(&quot;bottomleft&quot;, fill = colors, legend = V(Mw)$name, inset = 0.02, cex = 0.7, 
    bty = &quot;n&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/rfig/mangal_make_map_network.png&quot; alt=&quot;plot of chunk mangal_make_map_network&quot; /&gt; &lt;/p&gt;

&lt;p&gt;And here we are! It might not be the best-looking graph ever, but I was fairly surprised that it was so easy to produce.&lt;/p&gt;

&lt;h1 id=&quot;use-case-2-network-beta-diversity&quot;&gt;Use-case 2: network β-diversity&lt;/h1&gt;

&lt;p&gt;For use-case number two, I will use the functions in &lt;code&gt;betalink&lt;/code&gt; to do a quick illustration of how network β-diversity depends on the distance between two networks. In the first use case, we have created a &lt;code&gt;Matrices&lt;/code&gt; objects, which is a list of matrices. So we can simply do:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;bdiv &amp;lt;- betalink.dist(Matrices)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We’ll add the spatial distance between sites, using a function from the &lt;code&gt;sp&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;GeoDist &amp;lt;- spDists(as.matrix(Coord), longlat = TRUE)
colnames(GeoDist) &amp;lt;- rownames(GeoDist) &amp;lt;- rownames(Coord)
bdiv$Space &amp;lt;- as.dist(GeoDist)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And now, some plots:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;par(mfcol = c(1, 2))
with(bdiv, {
    plot(Space, WN, pch = 19, xlab = &quot;Distance (in km.)&quot;, ylab = &quot;Network dissim. (all species)&quot;)
    plot(Space, OS, pch = 19, xlab = &quot;Distance (in km.)&quot;, ylab = &quot;Network dissim. (common species)&quot;)
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/rfig/betadiv_rmangal_plots.png&quot; alt=&quot;plot of chunk betadiv_rmangal_plots&quot; /&gt; &lt;/p&gt;

&lt;p&gt;And here is a cool new mini-result: the dissimilarity of networks increases with distance overal, but not when you only account for the species which are shared between two locations.&lt;/p&gt;

&lt;h1 id=&quot;use-case-3-link-species-relationships&quot;&gt;Use-case 3: link-species relationships&lt;/h1&gt;

&lt;p&gt;Let’s end with a more classical example: in this system, what is the relationship between number of species (S), and number of interactions (L)? This information is super easy to get with a little bit of &lt;code&gt;plyr&lt;/code&gt; magic:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;LS &amp;lt;- ldply(Graphs, function(x) c(S = length(V(x)), L = length(E(x))))
head(LS)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##             .id  S  L
## 1  Tanjung Kopi 10  8
## 2 Tanjung Pisok  9  7
## 3        bahowo 11 10
## 4  Kampung Bajo  6  4
## 5    Batu Kapal  5  4
## 6         Bualo  9  8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The only thing left is to plot this table:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;plot(LS[, c(2, 3)], log = &quot;xy&quot;, xlab = &quot;Species&quot;, ylab = &quot;Links&quot;, pch = 19)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/rfig/mangal_demo_ls_png.png&quot; alt=&quot;plot of chunk mangal_demo_ls.png&quot; /&gt; &lt;/p&gt;

&lt;p&gt;We find the expect positive, log/log relationship. And it only required three lines of code!&lt;/p&gt;

&lt;h1 id=&quot;to-conclude&quot;&gt;To conclude&lt;/h1&gt;

&lt;p&gt;These three use cases are (I think) good examples of what can be done with the &lt;code&gt;rmangal&lt;/code&gt; package. I’ll refine them a little bit to add in the paper. If you have nay any suggestions, that would be greatly appreciated as well!&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>Uploading data into mangal</title>
     <link href="http://timotheepoisot.fr/2014/01/08/mangal-add-data/"/>
    <updated>2014-01-08T00:00:00-05:00</updated>
    <content type="html">&lt;p&gt;In the first part, I introduced &lt;code&gt;mangal&lt;/code&gt;, the database and associated &lt;code&gt;R&lt;/code&gt; package to interact with ecological networks. In the second part, I’ll give an overview of how to upload and curate your data. In the last part, we used functions starting with &lt;code&gt;get&lt;/code&gt; and &lt;code&gt;list&lt;/code&gt;. This time, we will use the &lt;code&gt;add&lt;/code&gt; and &lt;code&gt;patch&lt;/code&gt; functions, as they allow to change resouces on the server. There are a few important informations to have before we start.&lt;/p&gt;

&lt;p&gt;First, working on the server is &lt;em&gt;for real&lt;/em&gt;, so please be careful. But take the opportunity of the testing phase to try to break the database in new, innovative ways! Second, the licence under which the data are released is the &lt;em&gt;CC-0&lt;/em&gt; waiver. In short, when data are uploaded in the database, they are frelly available, for all to see and use. Almost all data sharing services use this license for data. Finally, the database is &lt;em&gt;add-only&lt;/em&gt;, which means that you can’t remove data (but I can, in case things go exceptionally wrong).&lt;/p&gt;

&lt;p&gt;In this post, we’ll see (i) how to create an account on the database, (ii)
how to create and populate a dataset, and (iii) how to modify the interactions
after sending them. You are of coure invited to try similar things. Note
that the database won’t accept objects with duplicated names, so if you try
to re-upload some of the taxa in this example, it most likely won’t work.&lt;/p&gt;

&lt;h1 id=&quot;setting-things-up&quot;&gt;Setting things up&lt;/h1&gt;

&lt;p&gt;As always, we’ll start by getting the latest release of &lt;code&gt;rmangal&lt;/code&gt;. And we’ll also get the latest release of &lt;code&gt;taxize&lt;/code&gt;, because there is a really neat trick I want to show you (in short: automated curation).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;options(stringsAsFactors = FALSE)
if (getOption(&quot;unzip&quot;) == &quot;&quot;) options(unzip = &quot;unzip&quot;)
library(devtools)
install_github(&quot;rmangal&quot;, &quot;mangal-wg&quot;)
library(rmangal)
install_github(&quot;taxize&quot;, &quot;ropensci&quot;)
library(taxize)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&quot;signing-up&quot;&gt;Signing-up&lt;/h1&gt;

&lt;p&gt;Uploading and curating data require that you are logged in. The reason is simple: each object in the database has an &lt;code&gt;owner&lt;/code&gt; property, and this owner becomes you every time you modify an object. Signing up can be done directly from &lt;code&gt;R&lt;/code&gt;: &lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;api &amp;lt;- mangalapi()
me &amp;lt;- signUp(api, &quot;my_user_name&quot;, &quot;my_password&quot;)
# This line will log you with your newly acquired identifiers!
api &amp;lt;- mangalapi(usr = me$username, pwd = me$password)
me
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $email
## [1] &quot;&quot;
## 
## $first_name
## [1] &quot;&quot;
## 
## $id
## [1] 3
## 
## $last_name
## [1] &quot;&quot;
## 
## $password
## [1] &quot;my_password&quot;
## 
## $username
## [1] &quot;my_user_name&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Before we start, let’s add some personal informations to your profile:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;me$first_name &amp;lt;- &quot;Fake&quot;
me$last_name &amp;lt;- &quot;People&quot;
me$email &amp;lt;- &quot;me@fake.people&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we just need to update this information on the server:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;me &amp;lt;- patchUser(api, me)
me
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $email
## [1] &quot;me@fake.people&quot;
## 
## $first_name
## [1] &quot;Fake&quot;
## 
## $id
## [1] 3
## 
## $last_name
## [1] &quot;People&quot;
## 
## $password
## [1] &quot;my_password&quot;
## 
## $username
## [1] &quot;my_user_name&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next time you want to work on data, you’ll just need to start your session by&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;api &amp;lt;- mangalapi(URL, usr = &quot;my_username&quot;, pwd = &quot;my_password&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&quot;putting-data-on-the-database&quot;&gt;Putting data on the database&lt;/h1&gt;

&lt;p&gt;In the previous part, I may have mentionned that the usual way to get a network is to start at the &lt;code&gt;dataset&lt;/code&gt; level, then go all the way down to the &lt;code&gt;taxa&lt;/code&gt;. When uploading data, you need to follow the opposite direction. Let’s say that we want to send data about what (probably) happens in the &lt;em&gt;Isle Royale National Park&lt;/em&gt;: wolves eat mooses, mooses eat balsam fir.&lt;/p&gt;

&lt;p&gt;As for &lt;code&gt;get&lt;/code&gt; and &lt;code&gt;list&lt;/code&gt;, the functions to modify data follow a single naming convention: either &lt;code&gt;patch&lt;/code&gt; or &lt;code&gt;add&lt;/code&gt;, and the name of the resource with its first letter capitalized.&lt;/p&gt;

&lt;h2 id=&quot;creating-taxa&quot;&gt;Creating taxa&lt;/h2&gt;

&lt;p&gt;The first thing we need to do is create a few &lt;code&gt;taxa&lt;/code&gt; objects. In case you don’t remember how a &lt;code&gt;taxa&lt;/code&gt; is formatted, you can call&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;whatIs(api, &quot;taxa&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##         field                                        help    type  null
## 1        bold             The BOLD identifier of the taxa integer  TRUE
## 2 description             A short description of the taxa  string  TRUE
## 3        gbif             The GBIF identifier of the taxa integer  TRUE
## 5        itis             The ITIS identifier of the taxa integer  TRUE
## 6        name             The scientific name of the taxa  string FALSE
## 7        ncbi    The NCBI Taxonomy identifier of the taxa integer  TRUE
## 9  vernacular The vernacular name of the taxa, in English  string FALSE
##   unique values
## 1   TRUE       
## 2  FALSE       
## 3   TRUE       
## 5   TRUE       
## 6   TRUE       
## 7   TRUE       
## 9  FALSE
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So we’ll want to create three taxa:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;moose &amp;lt;- list(name = &quot;Alces americanus&quot;, vernacular = &quot;American moose&quot;)
wolf &amp;lt;- list(name = &quot;Canis lupus&quot;, vernacular = &quot;Gray wolf&quot;)
balsam &amp;lt;- list(name = &quot;Abies balsamea&quot;, vernacular = &quot;Balsam fir&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, let’s put them in the database:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;wolf &amp;lt;- addTaxa(api, wolf)
moose &amp;lt;- addTaxa(api, moose)
balsam &amp;lt;- addTaxa(api, balsam)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can check that our taxa are indeed in the database with&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;getTaxa(api, wolf$id)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $bold
## NULL
## 
## $description
## NULL
## 
## $gbif
## NULL
## 
## $id
## [1] &quot;20&quot;
## 
## $itis
## NULL
## 
## $name
## [1] &quot;Canis lupus&quot;
## 
## $ncbi
## NULL
## 
## $owner
## [1] &quot;my_user_name&quot;
## 
## $vernacular
## [1] &quot;Gray wolf&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;creating-interactions&quot;&gt;Creating interactions&lt;/h2&gt;

&lt;p&gt;We will now create interactions between these taxa. Once more, have a look at &lt;code&gt;whatIs(api, &#39;interaction&#39;)&lt;/code&gt;, and in particular pay attention to the &lt;code&gt;values&lt;/code&gt; column of the &lt;code&gt;ecotype&lt;/code&gt; field. It tells you that &lt;code&gt;ecotype&lt;/code&gt; (the type of ecological interaction betwee two organisms), can only be one of:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;strsplit(subset(whatIs(api, &quot;interaction&quot;), field == &quot;ecotype&quot;)$values, &quot;, &quot;)[[1]]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] &quot;predation&quot;                 &quot;ectoparasitism&quot;           
##  [3] &quot;endoparasitism&quot;            &quot;intra-cellular parasitism&quot;
##  [5] &quot;parasitoidism&quot;             &quot;mycoheterotrophy&quot;         
##  [7] &quot;antixenosis&quot;               &quot;teletoxy&quot;                 
##  [9] &quot;amensalism&quot;                &quot;antibiosis&quot;               
## [11] &quot;allelopathy&quot;               &quot;competition&quot;              
## [13] &quot;facilitation&quot;              &quot;refuge creation&quot;          
## [15] &quot;inquilinism&quot;               &quot;phoresis&quot;                 
## [17] &quot;epibiosis&quot;                 &quot;pollination&quot;              
## [19] &quot;mutualistic symbiosis&quot;     &quot;zoochory&quot;                 
## [21] &quot;mutual protection&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that this list of terms will probably increase in the future. In any case, we have enough informations to start writing our interactions:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;w_e_m &amp;lt;- list(taxa_from = wolf, taxa_to = moose, ecotype = &quot;predation&quot;)
m_e_b &amp;lt;- list(taxa_from = moose, taxa_to = balsam, ecotype = &quot;herbivory&quot;)
w_e_m &amp;lt;- addInteraction(api, w_e_m)
m_e_b &amp;lt;- addInteraction(api, m_e_b)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Congratulations! Note that within the &lt;code&gt;R&lt;/code&gt; package, it’s perfectly acceptable to pass the whole &lt;code&gt;taxa&lt;/code&gt; object (but if you want to interact with the API, you need to pass only the URI, and if you want to interact directly with the API, chances are you knew that already…).&lt;/p&gt;

&lt;h2 id=&quot;wrapping-things-up&quot;&gt;Wrapping things up&lt;/h2&gt;

&lt;p&gt;At this point, we’re almost done. We simply need to wrap our interactions in a &lt;code&gt;network&lt;/code&gt; object:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;isle_royale &amp;lt;- addNetwork(api, list(name = &quot;Isle Royale National Park&quot;, description = &quot;Or at least a simplified version of it&quot;, 
    interactions = list(w_e_m, m_e_b), metaweb = TRUE))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;metaweb&lt;/code&gt; attribute comes from our &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pubmed/22994257&quot;&gt;paper on network beta-diversity&lt;/a&gt;. If you are reporting regionally observed or infered interactions, then it is &lt;code&gt;TRUE&lt;/code&gt;. if you have been sitting in the field looking at stuff, then it’s &lt;code&gt;FALSE&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;And finally, even if we only have one network, we will publish it as a dataset:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;ir_dataset &amp;lt;- addDataset(api, list(name = &quot;North-American Terrestrial food webs&quot;, 
    networks = list(isle_royale)))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And we’re done!&lt;/p&gt;

&lt;h1 id=&quot;modifying-data&quot;&gt;Modifying data&lt;/h1&gt;

&lt;p&gt;In this part, we will go through the different ways to alter data already in the database.&lt;/p&gt;

&lt;h2 id=&quot;adding-some-attributes&quot;&gt;Adding some attributes&lt;/h2&gt;

&lt;p&gt;Now, let’s add some informations to our data. First, we have told almost nothing about where our network is in space. We’ll pull it from the database, and add the &lt;code&gt;latitude&lt;/code&gt; and &lt;code&gt;longitude&lt;/code&gt; attribute:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;isle_royale &amp;lt;- getNetwork(api, isle_royale$id)
isle_royale$latitude &amp;lt;- 48.015
isle_royale$longitude &amp;lt;- -88.831
isle_royale &amp;lt;- patchNetwork(api, isle_royale)
isle_royale
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $date
## NULL
## 
## $description
## [1] &quot;Or at least a simplified version of it&quot;
## 
## $environment
## list()
## 
## $id
## [1] &quot;3&quot;
## 
## $interactions
## [1] &quot;18&quot; &quot;19&quot;
## 
## $latitude
## [1] &quot;48.015&quot;
## 
## $longitude
## [1] &quot;-88.831&quot;
## 
## $metaweb
## [1] TRUE
## 
## $name
## [1] &quot;Isle Royale National Park&quot;
## 
## $owner
## [1] &quot;my_user_name&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Because the &lt;code&gt;ir_dataset&lt;/code&gt; dataset contains a &lt;em&gt;reference&lt;/em&gt; to the object we just modified, there is no need to alter it in any way.&lt;/p&gt;

&lt;p&gt;At this point, you can have a look at &lt;code&gt;http://mangal.uqar.ca/data/&lt;/code&gt;, and on the map, there should be a little dot somewhere between Ontario and Wisconsin, representing the network.&lt;/p&gt;

&lt;h2 id=&quot;adding-new-relations&quot;&gt;Adding new relations&lt;/h2&gt;

&lt;p&gt;Let’s say that we want to provide a short bibliography along with the data. An important paper on this system is &lt;em&gt;The Rise and Fall of Isle Royale Wolves&lt;/em&gt;, by Peterson &amp;amp; Page. We know the DOI of this article (&lt;code&gt;10.2307/1381751&lt;/code&gt;), so we’ll just add a reference to the dataset. Datasets have &lt;code&gt;papers&lt;/code&gt; and &lt;code&gt;data&lt;/code&gt; fields, that point to &lt;code&gt;reference&lt;/code&gt; objects. First, we will create a reference (again, look at &lt;code&gt;whatIs(api, &#39;reference&#39;)&lt;/code&gt; to see the possible field (and beware, there is a typo, the &lt;code&gt;jstorid&lt;/code&gt; field is called &lt;code&gt;jsonid&lt;/code&gt;, I will fix that really soon). &lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;peterson_n_page &amp;lt;- addReference(api, list(doi = &quot;10.2307/1381751&quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, we need to add the reference to the &lt;code&gt;papers&lt;/code&gt; field of the &lt;code&gt;dataset&lt;/code&gt; object:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;ir_dataset$papers &amp;lt;- list(peterson_n_page)
ir_dataset &amp;lt;- patchDataset(api, ir_dataset)
ir_dataset
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $data
## list()
## 
## $description
## NULL
## 
## $id
## [1] &quot;2&quot;
## 
## $name
## [1] &quot;North-American Terrestrial food webs&quot;
## 
## $networks
## [1] &quot;3&quot;
## 
## $owner
## [1] &quot;my_user_name&quot;
## 
## $papers
## [1] &quot;1&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And if you go to &lt;code&gt;http://mangal.uqar.ca/data/dataset/&amp;lt;id&amp;gt;/&lt;/code&gt; (where &lt;code&gt;&amp;lt;id&amp;gt;&lt;/code&gt; is whatever number is in the &lt;code&gt;id&lt;/code&gt; field of the dataset), you will see a list of the references.&lt;/p&gt;

&lt;h2 id=&quot;using-the-power-of-open-science-for-good&quot;&gt;Using the power of open science for good&lt;/h2&gt;

&lt;p&gt;When describing the taxa, we only gave the latin and vernacular names. It’s good, but if we want to really take advantage of all the great tools we have, we will need a little more. One solution is to do a bit of googling, and just copy/paste the taxonomic identifiers and patch the taxa this way. Another solution is to use &lt;code&gt;taxize&lt;/code&gt;. &lt;code&gt;taxize&lt;/code&gt; has a function to get the NCBI identifiers from the latin name, which is perfect for our case:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;for (tax in list(wolf, moose, balsam)) {
    if (is.null(tax$ncbi)) {
        identifier &amp;lt;- get_uid(tax$name, ask = FALSE)
        if (!is.na(identifier)) {
            tax$ncbi &amp;lt;- identifier[1]
            patchTaxa(api, tax)
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## 
## Retrieving data for taxon &#39;Canis lupus&#39;
## 
## 
## Retrieving data for taxon &#39;Alces americanus&#39;
## 
## 
## Retrieving data for taxon &#39;Abies balsamea&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let’s get the whole network and see that the NCBI identifiers have been added:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;g &amp;lt;- network_as_graph(api, isle_royale$id)
unlist(V(g)$ncbi)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 999462  90345   9612
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There is probably more and more we can do using combination of packages, I’ll try to show some possibilities in use-cases.&lt;/p&gt;

&lt;h1 id=&quot;what-now&quot;&gt;What now?&lt;/h1&gt;

&lt;p&gt;As before, keep in mind that the test database will be periodically wiped
clean, so don’t use it to do some actual data deposition (yet). But it would
be really cool for you to try writing scripts to upload/modify your datasets,
and tell me if anything goes wrong. Meanwhile, I’m working on preparing
use cases (including one to automatically upload your data on &lt;em&gt;figshare&lt;/em&gt;
and returning the DOI), which I’ll publish (hopefully) later this week,
or early next week. As always, use the &lt;a href=&quot;https://github.com/mangal-wg/rmangal/issues?state=open&quot;&gt;GitHub page&lt;/a&gt; to report issues.&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>Introducing mangal, a database for ecological networks</title>
     <link href="http://timotheepoisot.fr/2014/01/07/mangal-database-networks/"/>
    <updated>2014-01-07T00:00:00-05:00</updated>
    <content type="html">&lt;p&gt;Working with data on ecological networks is usually a huge mess. Most of the
time, what you have is a series of matrices with &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt;, and in the best
cases, another file with some associated metadata. The other issue is that,
simply put, data on ecological networks are hard to get. The &lt;a href=&quot;http://www.nceas.ucsb.edu/interactionweb/&quot;&gt;&lt;em&gt;Interaction Web
Database&lt;/em&gt;&lt;/a&gt; has some, but it’s not as actively maintained as it should,
and the data are not standardized in any way. When you need to pull a lot
of networks to compare them, it means that you need to go through a long,
tedious, and error-prone process of cleaning and preparing the data. It
should not be that way, and that is the particular problem I’ve been trying
to solve since this spring.&lt;/p&gt;

&lt;p&gt;About a year ago, I discussed why &lt;a href=&quot;http://timotheepoisot.fr/2012/11/23/how-to-represent-networks/&quot;&gt;we should have a common language&lt;/a&gt;
to represent interaction networks. So with this idea in mind, and with
great feedback from colleagues, I assembled a series of &lt;code&gt;JSON&lt;/code&gt; schemes to
represent networks, in a way that will allow programmatic interaction with the
data. And I’m now super glad to announce that I am looking for beta-testers,
before I release the tool in a formal way. This post is the first part of a
series of two or three posts, which will give informations about the project,
how to interact with the database, and how to contribute data. I’ll probably
try to write a few use-cases, but if reading these posts inspire you, feel
free to suggest some!&lt;/p&gt;

&lt;h1 id=&quot;so-what-is-that-about&quot;&gt;So what is that about?&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;mangal&lt;/code&gt; (another word for a mangrove, and a type of barbecue) is a way to
represent and interact with networks in a way that is (i) relatively easy and
(ii) allows for powerful analyses. It’s built around a data format, &lt;em&gt;i.e.&lt;/em&gt;
a common language to represent ecological networks. You can have an overview
of the data format &lt;a href=&quot;http://mangal.uqar.ca/doc/spec/&quot;&gt;on the website&lt;/a&gt;. The data format was conceived with
two ideas in mind. First, it must makes sense from an ecological point of
view. Second, it must be easy to use to exchange data, send them to database,
and get them through APIs. Going on a website to download a text file (or
an Excel one) should be a thing of the past, and the data format is built
around the idea that everything should be done in a programmatic way.&lt;/p&gt;

&lt;p&gt;Very importantly, the data specification explains how data should be formatted
when they are &lt;em&gt;exchanged&lt;/em&gt;, not when they are used. The &lt;code&gt;R&lt;/code&gt; package, notably,
uses &lt;code&gt;igraph&lt;/code&gt; to manipulate networks. It means that anyone with a database
of ecological networks can write an API to expose these data in the &lt;code&gt;mangal&lt;/code&gt;
format, and in turn, anyone can access the data with the URL of the API as
the only information.&lt;/p&gt;

&lt;p&gt;Because everyone uses &lt;code&gt;R&lt;/code&gt;, as I’ve mentionned above, we are also releasing
a &lt;code&gt;R&lt;/code&gt; package (unimaginatively titled &lt;code&gt;rmangal&lt;/code&gt;). You can &lt;a href=&quot;https://github.com/mangal-wg/rmangal&quot;&gt;get it from
&lt;em&gt;GitHub&lt;/em&gt;&lt;/a&gt;, and we’ll see in a minute how to install it until it
is released on CRAN. Most of these posts will deal with how to use the &lt;code&gt;R&lt;/code&gt;
package, and what can be done with it. Ideally, you won’t need to go on the
website &lt;em&gt;at all&lt;/em&gt; to interact with the data (but just to make sure you do, the
website has some nice eye-candy, with clickable maps and animated networks).&lt;/p&gt;

&lt;h1 id=&quot;things-to-know-before-getting-started&quot;&gt;Things to know before getting started&lt;/h1&gt;

&lt;p&gt;As I’ve mentionned above, I’m looking for people to give the database
and package a test before I move on with the release. A &lt;strong&gt;very important
point&lt;/strong&gt; is that, because this is a testing period, the database will be
emptied quiet frequently. So do not share what you put on the database at
the moment. Basically, until the first version of the &lt;code&gt;rmangal&lt;/code&gt; package hits
CRAN, consider that all data may be wiped at any moment.&lt;/p&gt;

&lt;h2 id=&quot;the-necessary-r-packages&quot;&gt;The necessary R packages&lt;/h2&gt;

&lt;p&gt;The &lt;code&gt;rmangal&lt;/code&gt; package requires a few others things to work with (but if you
are using any of the &lt;a href=&quot;http://ropensci.org/&quot;&gt;rOpenSci&lt;/a&gt; packages, chances are you already
have most of them. In any case, the installation will take care of getting
any required dependencies, so install &lt;code&gt;devtools&lt;/code&gt; if you don’t have it, and run:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;options(stringsAsFactors = FALSE)
if (getOption(&quot;unzip&quot;) == &quot;&quot;) options(unzip = &quot;unzip&quot;)
library(devtools)
install_github(&quot;rmangal&quot;, &quot;mangal-wg&quot;)
library(rmangal)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will pull the most recent version from the &lt;em&gt;GitHub&lt;/em&gt; repository of the
package, so it’s a good idea to run that at the beginning of each session.&lt;/p&gt;

&lt;h2 id=&quot;how-to-report-problems-and-suggest-improvements&quot;&gt;How to report problems and suggest improvements&lt;/h2&gt;

&lt;p&gt;The best place to report problems is the &lt;a href=&quot;https://github.com/mangal-wg/rmangal/issues&quot;&gt;Issues page&lt;/a&gt; of the &lt;code&gt;rmangal&lt;/code&gt;
repository. Suggestions of improvements are particularly welcome. The code
for the API is not open-sourced at the moment, because I have a fair amount
of work to do to make it easy to install.&lt;/p&gt;

&lt;h2 id=&quot;how-to-get-more-informations&quot;&gt;How to get more informations?&lt;/h2&gt;

&lt;p&gt;In the &lt;a href=&quot;https://github.com/mangal-wg/rmangal/tree/master/vignettes&quot;&gt;repository of the package&lt;/a&gt;, there is a series of (in progress)
vignettes. They give a little bit more background on what is going on.&lt;/p&gt;

&lt;h1 id=&quot;getting-data-from-r&quot;&gt;Getting data from R&lt;/h1&gt;

&lt;p&gt;OK, let’s get started!&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;first&lt;/em&gt; thing you have to do is create a &lt;code&gt;R&lt;/code&gt; object with
the URL of the API you want to connect to. By default, this is
&lt;code&gt;http://mangal.uqar.ca/api/v1/&lt;/code&gt;. Note that there are arguments for username
and password, but we’ll get to those in the second post.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;api &amp;lt;- mangalapi()
names(api)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] &quot;base&quot;        &quot;trail&quot;       &quot;dataset&quot;     &quot;environment&quot; &quot;interaction&quot;
##  [6] &quot;item&quot;        &quot;network&quot;     &quot;population&quot;  &quot;reference&quot;   &quot;taxa&quot;       
## [11] &quot;trait&quot;       &quot;user&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;names&lt;/code&gt; options is a list of all of the properties of the API. Aside from &lt;code&gt;base&lt;/code&gt; and &lt;code&gt;trail&lt;/code&gt; (and if you are logged-in, &lt;code&gt;me&lt;/code&gt; and &lt;code&gt;auth&lt;/code&gt;), they all resources you can interact with. For example&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;api$taxa
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $url
## [1] &quot;http://mangal.uqar.ca/api/v1/taxa/&quot;
## 
## $verbs
## [1] &quot;get&quot;   &quot;post&quot;  &quot;patch&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This gives you two informations. First, the URL to do anything related with taxa (&lt;code&gt;api$taxa$url&lt;/code&gt;), and the versb you can use. Verbs are a way to represent actions when talking to a server. I’m not going to go into much details at this point, but here is the gist: &lt;code&gt;get&lt;/code&gt; will retrieve information, &lt;code&gt;post&lt;/code&gt; will add it, and &lt;code&gt;patch&lt;/code&gt; will modify it. Butyou don’t have to know any of that to use the package.&lt;/p&gt;

&lt;p&gt;The functions to interact with the data in &lt;code&gt;rmangal&lt;/code&gt; are all following a naming convention: first the action, then the type of object. The actions are &lt;code&gt;list&lt;/code&gt; and &lt;code&gt;get&lt;/code&gt; (and &lt;code&gt;add&lt;/code&gt; and &lt;code&gt;patch&lt;/code&gt;, which we’ll see in the next post), and the type of objects are what was returned by &lt;code&gt;names(api)&lt;/code&gt;, with the first letter capitalized.&lt;/p&gt;

&lt;h2 id=&quot;first-step---a-list-of-all-taxa&quot;&gt;First step - a list of all taxa&lt;/h2&gt;

&lt;p&gt;So, if you want to have a list of all the taxa in the database, it’s as simple as doing the following (a bit of &lt;code&gt;plyr&lt;/code&gt; magic to have a nice &lt;code&gt;data.frame&lt;/code&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;all_taxa &amp;lt;- listTaxa(api)
head(data.frame(laply(all_taxa, function(x) x)), 3)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   bold description gbif id itis                    name ncbi   owner
## 1 NULL        NULL NULL  9 NULL Lamellodiscus ignoratus NULL tpoisot
## 2 NULL        NULL NULL 10 NULL   Lamellodiscus elegans NULL tpoisot
## 3 NULL        NULL NULL 11 NULL   Lamellodiscus ergensi NULL tpoisot
##                vernacular
## 1 Lamellodiscus ignoratus
## 2   Lamellodiscus elegans
## 3   Lamellodiscus ergensi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And let’s look at the first element of &lt;code&gt;all_taxa&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;all_taxa[[1]]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $bold
## NULL
## 
## $description
## NULL
## 
## $gbif
## NULL
## 
## $id
## [1] &quot;9&quot;
## 
## $itis
## NULL
## 
## $name
## [1] &quot;Lamellodiscus ignoratus&quot;
## 
## $ncbi
## NULL
## 
## $owner
## [1] &quot;tpoisot&quot;
## 
## $vernacular
## [1] &quot;Lamellodiscus ignoratus&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So what are all these fields? There is a &lt;code&gt;whatIs&lt;/code&gt; function in &lt;code&gt;rmangal&lt;/code&gt;, whose purpose is to tell you everything you need to know about a type of object. Let’s do that with &lt;code&gt;taxa&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;whatIs(api, &quot;taxa&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##         field                                        help    type  null
## 1        bold             The BOLD identifier of the taxa integer  TRUE
## 2 description             A short description of the taxa  string  TRUE
## 3        gbif             The GBIF identifier of the taxa integer  TRUE
## 5        itis             The ITIS identifier of the taxa integer  TRUE
## 6        name             The scientific name of the taxa  string FALSE
## 7        ncbi    The NCBI Taxonomy identifier of the taxa integer  TRUE
## 9  vernacular The vernacular name of the taxa, in English  string FALSE
##   unique values
## 1   TRUE       
## 2  FALSE       
## 3   TRUE       
## 5   TRUE       
## 6   TRUE       
## 7   TRUE       
## 9  FALSE
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first column is the name of the field, the second is a description of the data, and the &lt;code&gt;type&lt;/code&gt; column is the format of the field content. The &lt;code&gt;null&lt;/code&gt; column will tell you whether the field can be &lt;code&gt;NULL&lt;/code&gt; or not. The &lt;code&gt;unique&lt;/code&gt; column will tell you whether two different objects can share a value for this field (in the example of &lt;code&gt;taxa&lt;/code&gt;, we see that no two taxa can have the same indetifiers or latin name). Finally, the &lt;code&gt;values&lt;/code&gt; column is set &lt;em&gt;only&lt;/em&gt; when a field accepts a particular set of values.&lt;/p&gt;

&lt;p&gt;Another way to get the first &lt;code&gt;taxa&lt;/code&gt; if we know its &lt;code&gt;id&lt;/code&gt; is&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;getTaxa(api, all_taxa[[1]]$id)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $bold
## NULL
## 
## $description
## NULL
## 
## $gbif
## NULL
## 
## $id
## [1] &quot;9&quot;
## 
## $itis
## NULL
## 
## $name
## [1] &quot;Lamellodiscus ignoratus&quot;
## 
## $ncbi
## NULL
## 
## $owner
## [1] &quot;tpoisot&quot;
## 
## $vernacular
## [1] &quot;Lamellodiscus ignoratus&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;getting-real-data&quot;&gt;Getting real data&lt;/h2&gt;

&lt;p&gt;The most frequent use will be to look at &lt;code&gt;dataset&lt;/code&gt;s, and get the data within. After looking at the data specification, you’ll reach the conclusion that a &lt;code&gt;dataset&lt;/code&gt; is mostly a list of &lt;code&gt;network&lt;/code&gt;s, which are themselves lists of &lt;code&gt;interactions&lt;/code&gt;, which point to &lt;code&gt;taxa&lt;/code&gt; objects (among other things - it’s explained in the vignettes).&lt;/p&gt;

&lt;p&gt;First thing first, let’s have a look at the datasets:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;(all_ds &amp;lt;- ldply(listDataset(api), function(x) unlist(x)))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   description id                                              name
## 1              1 Host-parasite interactions in marine environments
##   networks    owner
## 1        2 poisti01
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that you can also &lt;a href=&quot;http://mangal.uqar.ca/data/&quot;&gt;browse the data&lt;/a&gt; from the website, where there are animated maps, and cool dynamical representations of the networks. But meanwhile, let’s get the first dataset:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;(ds &amp;lt;- getDataset(api, all_ds$id[1]))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $data
## list()
## 
## $description
## [1] &quot;&quot;
## 
## $id
## [1] &quot;1&quot;
## 
## $name
## [1] &quot;Host-parasite interactions in marine environments&quot;
## 
## $networks
## [1] &quot;2&quot;
## 
## $owner
## [1] &quot;poisti01&quot;
## 
## $papers
## list()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This dataset has a single network (of &lt;code&gt;id&lt;/code&gt; 2), which looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;getNetwork(api, ds$networks[1])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $date
## [1] &quot;2007/04/05&quot;
## 
## $description
## [1] &quot;&quot;
## 
## $environment
## list()
## 
## $id
## [1] &quot;2&quot;
## 
## $interactions
##  [1] &quot;3&quot;  &quot;4&quot;  &quot;5&quot;  &quot;6&quot;  &quot;7&quot;  &quot;8&quot;  &quot;9&quot;  &quot;10&quot; &quot;11&quot; &quot;12&quot; &quot;13&quot; &quot;14&quot; &quot;15&quot; &quot;16&quot;
## [15] &quot;17&quot;
## 
## $latitude
## [1] &quot;42.482&quot;
## 
## $longitude
## [1] &quot;3.137&quot;
## 
## $metaweb
## [1] TRUE
## 
## $name
## [1] &quot;Lamellodiscus of sparids in the Banyuls Bay Area&quot;
## 
## $owner
## [1] &quot;poisti01&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So the process of getting an entire network is calling &lt;code&gt;getInteraction&lt;/code&gt; on each interaction, see which &lt;code&gt;taxa&lt;/code&gt; it involves, then call &lt;code&gt;getTaxa&lt;/code&gt; on each of those, and so forth. But as this is extremely boring, there is a &lt;code&gt;network_as_graph&lt;/code&gt; function, which is doing exactly that:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;g &amp;lt;- network_as_graph(api, ds$networks[1])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Because this function will have to go through (possibly) a lot of resources to find the whole network, and because getting each resource requires an interaction with the server, it can be long. The good strategy is, rather obviously, to decide which objects to store, and interact with them locally, rather than querying the database everytime you want to see what’s in a network. The &lt;code&gt;g&lt;/code&gt; object created this way is an &lt;code&gt;igraph&lt;/code&gt; graph, meaning that we can plot it:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;plot(g, edge.arrow.size = 0.5, vertex.size = 30, vertex.color = &quot;white&quot;, vertex.frame.color = NA, 
    vertex.label.family = &quot;sans&quot;, vertex.label.color = &quot;black&quot;, layout = layout.circle)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/rfig/rmangal_first_network.png&quot; alt=&quot;plot of chunk rmangal_first_network&quot; /&gt; &lt;/p&gt;

&lt;p&gt;Note also that because &lt;code&gt;g&lt;/code&gt; in an &lt;code&gt;igraph&lt;/code&gt; object, both the nodes and interactions have retained their attributes. So if you want to see what type of interactions (&lt;code&gt;whatIs&lt;/code&gt; will tell you that this is the &lt;code&gt;ecotype&lt;/code&gt; field of an &lt;code&gt;interaction&lt;/code&gt;) are in this network, this is as simple as:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;E(g)$ecotype
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] &quot;ectoparasitism&quot; &quot;ectoparasitism&quot; &quot;ectoparasitism&quot; &quot;ectoparasitism&quot;
##  [5] &quot;ectoparasitism&quot; &quot;ectoparasitism&quot; &quot;ectoparasitism&quot; &quot;ectoparasitism&quot;
##  [9] &quot;ectoparasitism&quot; &quot;ectoparasitism&quot; &quot;ectoparasitism&quot; &quot;ectoparasitism&quot;
## [13] &quot;ectoparasitism&quot; &quot;ectoparasitism&quot; &quot;ectoparasitism&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is an important idea behind the data specification. The &lt;em&gt;right&lt;/em&gt; way to store data and the &lt;em&gt;right&lt;/em&gt; way to work with these data are most likely different. Although some people will want to manipulate the data directly using the &lt;code&gt;get&lt;/code&gt; and &lt;code&gt;list&lt;/code&gt; functions, it’s always nice to have functions to speed up the process. And if you use &lt;code&gt;network_as_graph&lt;/code&gt;, and want to get a list of the NCBI identifiers of all the species, you don’t need to use &lt;code&gt;getTaxa&lt;/code&gt;; writing &lt;code&gt;V(g)$ncbi&lt;/code&gt; will do the trick.&lt;/p&gt;

&lt;h1 id=&quot;so-now-what&quot;&gt;So now what?&lt;/h1&gt;

&lt;p&gt;This is the end of the first part of this series of posts on &lt;code&gt;mangal&lt;/code&gt;. Later this week, I will publish the next part, about how to &lt;em&gt;upload&lt;/em&gt; your data in the database. This is where I’ll be looking for people to actually test how things work. Meanwhile, if you want to play with the package and report weird things, that’s cool!&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>Understanding the variation of species interactions</title>
     <link href="http://timotheepoisot.fr/2014/01/03/variation-species-interactions/"/>
    <updated>2014-01-03T00:00:00-05:00</updated>
    <content type="html">&lt;p&gt;I spent most of the last two years thinking about &lt;em&gt;why&lt;/em&gt; species interaction
vary over time and space. The trouble is that, even though we have some
methodological tools, and some interesting observations, we lack a solid
framework to make sense of it all. So we (I, &lt;a href=&quot;http://www.stoufferlab.org/people/stouffer/&quot;&gt;Daniel Stouffer&lt;/a&gt; and
&lt;a href=&quot;http://chaire-eec.uqar.ca/&quot;&gt;Dominique Gravel&lt;/a&gt;) started thinking about the mechanisms involved
in the variation of species interactions. The paper is now available &lt;a href=&quot;http://biorxiv.org/content/early/2014/01/03/001677&quot;&gt;as
a preprint&lt;/a&gt; on &lt;em&gt;bioRxiV&lt;/em&gt; (the upload process is really smooth,
by the way), and will be submitted shortly.&lt;/p&gt;

&lt;p&gt;Interestingly, understanding why species interactions vary require that we
focus on &lt;em&gt;populations&lt;/em&gt;, rather than &lt;em&gt;species&lt;/em&gt;. Most of our argument is that
interactions vary because (i) local abundances change, and (ii) there is local
variation in traits distributions. &lt;span class=&quot;margin&quot;&gt;Gravel &lt;em&gt;et al.&lt;/em&gt; (2013)
Methods Ecol Evol &lt;a href=&quot;http://dx.doi.org/10.1111/2041-210X.12103&quot;&gt;DOI&lt;/a&gt;&lt;/span&gt;And so inferences
at the level of the species (such as we made using body size in food webs)
will give you an idea of what &lt;em&gt;can&lt;/em&gt; happen (regionally), but the observed
interactions (locally) will likely be different. The important point is that,
assuming we want to predict ecosystem properties from network structure,
it’s not really wise to &lt;em&gt;assume&lt;/em&gt; that interactions happen, because whether
they will happen or not depends, again, on local conditions.&lt;/p&gt;

&lt;p&gt;So whereas the “current” view of interaction networks is &lt;em&gt;a matrix of 0s
and 1s telling whether two species interact&lt;/em&gt;, it would make sense that we
think about these networks in terms of probability that the interaction
will happen. The interesting thing is that once everything is put together,
we are left with something that is close to a predictive framework:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
P(i \rightarrow j) \propto \mathcal{T}(i,j) \times \mathcal{N}(i, j) + \epsilon
&lt;/script&gt;

&lt;p&gt;, or in other words, the probability that &lt;em&gt;i&lt;/em&gt; and &lt;em&gt;j&lt;/em&gt; interact depends
on their traits (&lt;em&gt;T&lt;/em&gt;) and local abundances (&lt;em&gt;N&lt;/em&gt;). With a good assumption
about the shape of the &lt;em&gt;T&lt;/em&gt; and &lt;em&gt;N&lt;/em&gt; functions, which can be informed by some
observations in the field, then it should be possible to extrapolate the
probability than any pair of species will interact.&lt;/p&gt;

&lt;p&gt;As we discuss at length in the paper, this has some nice implications for
a very active line of research in biogeography, which seeks to integrate
species interactions into predictive models of species distribution. So if
you want to read more, here is the abstract, and the &lt;a href=&quot;http://biorxiv.org/content/early/2014/01/03/001677&quot;&gt;full text&lt;/a&gt;
is available online:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Community ecology is tasked with the considerable challenge of predicting the
structure, and properties, of emerging ecosystems. It requires the ability to
understand how and why species interact, as this will allow the development
of mechanism-based predictive models, and as such to better characterize
how ecological mechanisms act locally on the existence of inter-specific
interactions. Here we argue that the current conceptualization of species
interaction networks is ill-suited for this task. Instead, we propose that
future research must start to account for the intrinsic variability of
interaction networks. This can be accomplished simply by recognizing that
there exists intra-specific variability, in traits or properties related
to the establishment of species interactions. By shifting the scale towards
population-based processes, we show that this new approach will improve our
predictive ability and mechanistic understanding of how species interact
over biogeographical scales.&lt;/p&gt;
&lt;/blockquote&gt;

</content>
  </entry>
  
  <entry>
     <title>Using git throughout your workflow</title>
     <link href="http://timotheepoisot.fr/2014/01/02/git-workflow/"/>
    <updated>2014-01-02T00:00:00-05:00</updated>
    <content type="html">&lt;p&gt;There are good chances that I will give an introductory workshop to the many,
many uses of &lt;code&gt;git&lt;/code&gt; for scientists in the next weeks. What follows is a series
of notes about the things &lt;em&gt;I&lt;/em&gt; use &lt;code&gt;git&lt;/code&gt; for, which I will cover. In a way,
this post is a list of all the possible ways to introduce &lt;code&gt;git&lt;/code&gt; into your
workflow as a (computational) scientist. Some things are specific to &lt;code&gt;git&lt;/code&gt;
as a protocol, some others to &lt;em&gt;GitHub&lt;/em&gt; as a platform. I will try to make
the distinction clear.&lt;/p&gt;

&lt;h1 id=&quot;tracking-your-code&quot;&gt;Tracking your code&lt;/h1&gt;

&lt;p&gt;It would be tempting to discard this one if you are not mainly a computational
scientist. Please don’t. Even the simplest piece of code you write, the most
basic &lt;code&gt;R&lt;/code&gt; function is a &lt;em&gt;central&lt;/em&gt; step in your workflow if it is responsible
for transforming raw data into something you can show around (a figure,
or a table). In the most fundamental way, &lt;code&gt;git&lt;/code&gt; is a way for you to track
what you changed, and when. And you can &lt;em&gt;revert&lt;/em&gt; back to the previous state
of your code if you want.&lt;/p&gt;

&lt;p&gt;The most important feature of &lt;code&gt;git&lt;/code&gt; (in my opinion), and one that is shared
with most versioning systems, is the ability to (i) give the reasons of
a particular change, and (ii) see exactly what has been changed. See, for
example, what happens after &lt;em&gt;adding&lt;/em&gt; a few lines of code:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;diff&quot;&gt;&lt;span class=&quot;gu&quot;&gt;@@ -50,6 +50,11 @@&lt;/span&gt;
  #&amp;#39; }
  tax_agg &amp;lt;- function(x, rank, db = &amp;#39;ncbi&amp;#39;, ...) 
  {
 +  if(is.matrix(x))
 +  {
 +    if(is.null(colnames(x))) stop(&amp;quot;The community data matrix must have named columns&amp;quot;)
 +    x &amp;lt;- data.frame(x)
 +  }
    # bring to long format
    x$rownames &amp;lt;- rownames(x)
    df_m &amp;lt;- melt(x, id = &amp;#39;rownames&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If a change in your code breaks it, you can track the lines that where
modified, and start looking here for possible bugs.&lt;/p&gt;

&lt;h1 id=&quot;collaborative-manuscript-writing&quot;&gt;Collaborative manuscript writing&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;http://www.scfbm.org/content/8/1/7&quot;&gt;Karthik Ram&lt;/a&gt; went over this point at large in its paper, so I will keep
this point short. If you dread exchanging multiple versions of a paper over
email, and fear the day where you will have to handle conflicting edits, or
Word and OpenOffice will ruin your formatting, then look into &lt;code&gt;git&lt;/code&gt;. Although
it requires that you use &lt;em&gt;different&lt;/em&gt; formats to write (&lt;code&gt;markdown&lt;/code&gt; or &lt;code&gt;LaTeX&lt;/code&gt;),
the advantages are numerous (and yes, I count &lt;em&gt;not using Word&lt;/em&gt; as a &lt;em&gt;huge&lt;/em&gt;
advantage). You will have the same opportunity to track precisely what is
going on with a clear summary of the changes. And because &lt;code&gt;git&lt;/code&gt; handles
several people working concurrently just fine, you can have a lot happening:&lt;/p&gt;

&lt;p&gt;![Figure1][fig1]
[fig1]: /images/gitnetwork.png  “Figure 1”&lt;/p&gt;

&lt;h1 id=&quot;make-replying-to-reviewers-easy&quot;&gt;Make replying to reviewers &lt;em&gt;easy&lt;/em&gt;&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;http://carlboettiger.info/2013/06/10/mansucript-reviews-on-github.html&quot;&gt;Carl Boettiger&lt;/a&gt; and &lt;a href=&quot;https://github.com/trvrb/flux/issues?page=1&amp;amp;state=closed&quot;&gt;Trevor Bedford&lt;/a&gt; (and I, for some papers) use
&lt;em&gt;Issues&lt;/em&gt; as a way to handle reviewers comments. Issues are a paradigm taken
straight from software development, where a problem in your code needs to
be addressed. We make a point for the relevance of this metaphor in &lt;a href=&quot;https://github.com/PhDP/ms_scriptoria/blob/master/ms.md&quot;&gt;Phil’s
&lt;em&gt;in prep&lt;/em&gt; paper&lt;/a&gt; on the &lt;code&gt;scriptoria&lt;/code&gt; project. In short, you can
attribute each point raised by a referee to an Issue. You can then assign
Issues to people working on the manuscript, and track the progression of
the replies. Because most issues tracking systems come with a &lt;em&gt;Milestones&lt;/em&gt;
ability, you can assign all issues to the &lt;em&gt;Milestone&lt;/em&gt; “First revision”,
and set a deadline at which all the issues have to be fixed.&lt;/p&gt;

&lt;p&gt;As &lt;em&gt;GitHub&lt;/em&gt; allows you to reference &lt;em&gt;commits&lt;/em&gt; (&lt;em&gt;i.e.&lt;/em&gt; changes made to your
code/paper), it is really easy to say, in the reply to each point, what you
did to address it, and give a link to the &lt;code&gt;diff&lt;/code&gt; (&lt;em&gt;i.e.&lt;/em&gt; the list of all
changes). Instead of replying things like “&lt;em&gt;We replaced the sentence P.4
L.24-25 by a short statement (now P.6 L.14-21)&lt;/em&gt;”, you can say “&lt;em&gt;We changed
the text in the following way, …, see commit &lt;code&gt;e30b8e&lt;/code&gt;&lt;/em&gt;”. &lt;em&gt;GitHub&lt;/em&gt; will take
care of putting a link in place, and the reviewer can then see exactly which
changes were made. As a final note on this point: it’s obviously good practice
to &lt;em&gt;ask&lt;/em&gt; the editor if s/he agrees with the reviews being put on &lt;em&gt;GitHub&lt;/em&gt;.&lt;/p&gt;

&lt;h1 id=&quot;give-support-to-users&quot;&gt;Give support to users&lt;/h1&gt;

&lt;p&gt;The &lt;em&gt;Issues&lt;/em&gt; system works, obviously, for code. People using your code can
suggest improvements, or report bug. It is also possible to contribute new
code (through the &lt;em&gt;fork&lt;/em&gt;/&lt;em&gt;pull&lt;/em&gt; mechanism).&lt;/p&gt;

&lt;p&gt;One of the things I enjoy in the &lt;em&gt;Issues&lt;/em&gt; system is that it can (when the
people actually use it…) unclutter your mailbox. Instead of sending an email
to report a bug, people can submit an issue. You will have a clear list of
what to do, and then again, the ability to indicate exactly how you solved it.&lt;/p&gt;

&lt;h1 id=&quot;release-versions-for-publications&quot;&gt;Release versions for publications&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;GitHub&lt;/em&gt; (and probably other platforms) comes with a &lt;em&gt;release&lt;/em&gt; mechanism. You
can select one &lt;em&gt;commit&lt;/em&gt; and label it as something special (for example,
the version of a code you used to do the analysis presented in a paper). In
the context of manuscript writing, I use releases to identify major steps in
the life of a paper: first preprint, update to the preprint, revised version,
final revision, etc etc. You can see &lt;a href=&quot;https://github.com/tpoisot/ms_connectance_complexity/releases&quot;&gt;an example here&lt;/a&gt;. Reading through
a large number of commits can be a bore, but quickly browsing a list of
releases can give you a sense of when the important things happened. The
release mechanism is also, of course, useful for code.&lt;/p&gt;

&lt;h1 id=&quot;get-confident-in-your-code&quot;&gt;Get confident in your code&lt;/h1&gt;

&lt;p&gt;This is one of the features of &lt;em&gt;GitHub&lt;/em&gt; (and related tools) I hope to use more
and more in the future. I started looking into &lt;a href=&quot;https://travis-ci.org/&quot;&gt;TravisCI&lt;/a&gt; a month
or so ago, and I love it. In short, TravisCI is a &lt;em&gt;continuous integration&lt;/em&gt;
system: each time you commit a change to your code, it will run a pre-specified
series of steps to &lt;code&gt;build&lt;/code&gt; it, and tell you (and other people) whether it
was a success or not. The list of instructions to build your project can be
whatever you want (compiling the &lt;code&gt;LaTeX&lt;/code&gt; document, running the test suite,
…). But the central point is that you will know, in real time, if your
changes &lt;em&gt;still allow your code to run&lt;/em&gt; or not. Another related service is
&lt;a href=&quot;https://coveralls.io/&quot;&gt;coveralls&lt;/a&gt; - it gives you an overview of which proportion of your code is
covered by tests. These two services (TravisCI and coveralls) are automated,
so you have nothing to do to make sure that you code run, and that it is
covered by tests (except that coding well, and writing tests…). Both
services will allow you to display little badges on your project page,
so your &lt;em&gt;users&lt;/em&gt; can have some confidence in your code.&lt;/p&gt;

&lt;h1 id=&quot;a-terrible-way-to-showcase-your-work&quot;&gt;A terrible way to showcase your work&lt;/h1&gt;

&lt;p&gt;One thing for which social coding platforms are &lt;em&gt;not&lt;/em&gt; so good is showcasing
your work. This is why I now have a &lt;a href=&quot;http://timotheepoisot.fr/software/&quot;&gt;software&lt;/a&gt; page on this website. If you use
&lt;em&gt;GitHub&lt;/em&gt; to track of lot of things (and I do), what is important can often be
buried beneath a pile of your active-but-not-yet-useful projects. And because
the listing of your repositories is just the project name and a one-line
description, it’s not obvious what is important. So my recommendation if
your want to give people a broad overview of what you have been up to,
is to have a webpage with your projects, instead of just giving the URL to
your &lt;em&gt;GitHub&lt;/em&gt; account.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;And that’s the way I use &lt;code&gt;git&lt;/code&gt; in my everyday workflow. There is a bit of a
learning curve, but you can learn (most of) &lt;code&gt;git&lt;/code&gt; &lt;a href=&quot;http://try.github.io/levels/1/challenges/1&quot;&gt;in 15 minutes&lt;/a&gt;. And
it saves time in the long run, both because it simplifies some tedious tasks,
and because it gives you a single formalism in which you can inscribe your
daily activities.&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>Using Vim as a writing environment</title>
     <link href="http://timotheepoisot.fr/2014/01/01/vim-writing-environment/"/>
    <updated>2014-01-01T00:00:00-05:00</updated>
    <content type="html">&lt;p&gt;Happy new year, everyone! And to make sure it starts in a good way, let me
bring you the gift of productivity! Or specifically, how to set-up &lt;code&gt;Vim&lt;/code&gt;
in a way that will transform it into an impressively efficient writing
environment. &lt;code&gt;Vim&lt;/code&gt; is a really good code editor, there is no questioning
that. But writing code and writing prose are entirely different exercises,
and some tools you need to efficiently write code are only getting in the
way when you write prose. But &lt;code&gt;Vim&lt;/code&gt; can handle that, and I’m going to share
my configuration with you.&lt;/p&gt;

&lt;h2 id=&quot;the-font&quot;&gt;The font&lt;/h2&gt;

&lt;p&gt;I care &lt;em&gt;way too much&lt;/em&gt; about fonts and typography. And as I spend several
hours each days looking at a terminal, picking a good font for writing is
important. What makes a font good will vary from person to person, but there
are a few common elements. I want glyphs that are easy to differentiate (&lt;code&gt;0&lt;/code&gt;
&lt;em&gt;vs.&lt;/em&gt; &lt;code&gt;O&lt;/code&gt;, &lt;code&gt;l &lt;/code&gt; &lt;em&gt;vs.&lt;/em&gt; &lt;code&gt;1&lt;/code&gt;, for example), and a font with a good negative
space, so that reading long paragraphs of texts is not eye-straining. When
spending a few hours working on a paper, it can make all the difference in
the world to have a good, easily legible font. I use the &lt;a href=&quot;http://www.google.com/fonts/specimen/Cousine&quot;&gt;Cousine&lt;/a&gt; family,
which can be freely downloaded. It works well as all sizes, and has a good
inventory of glyphs.&lt;/p&gt;

&lt;h2 id=&quot;the-color-scheme&quot;&gt;The color scheme&lt;/h2&gt;

&lt;p&gt;No surprise, I use &lt;a href=&quot;http://ethanschoonover.com/solarized&quot;&gt;Solarized&lt;/a&gt; (light). It has a good contrast, and because
of the beige background, you don’t feel like you are staring at a light
bulb. And the &lt;code&gt;solarized-vim&lt;/code&gt; version comes with quite a very exhaustive
syntax set, so everything (i) works and (ii) looks great out of the box.&lt;/p&gt;

&lt;h2 id=&quot;the-plugins&quot;&gt;The plugins&lt;/h2&gt;

&lt;p&gt;Although you can get my entire &lt;a href=&quot;https://github.com/tpoisot/dotfiles/blob/master/vimrc&quot;&gt;&lt;code&gt;.vimrc&lt;/code&gt; file&lt;/a&gt; from &lt;em&gt;GitHub&lt;/em&gt;, I
will just walk you through the most important plugins. I manage them using
&lt;a href=&quot;https://github.com/gmarik/vundle&quot;&gt;vundle&lt;/a&gt;, and the ones I &lt;em&gt;absolutely need&lt;/em&gt; to do some serious writing are:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;vim&quot;&gt;Bundle &lt;span class=&quot;s1&quot;&gt;&amp;#39;tpope/vim-markdown&amp;#39;&lt;/span&gt;
Bundle &lt;span class=&quot;s1&quot;&gt;&amp;#39;mikewest/vimroom&amp;#39;&lt;/span&gt;
Bundle &lt;span class=&quot;s1&quot;&gt;&amp;#39;vim-pandoc/vim-pandoc&amp;#39;&lt;/span&gt;
Bundle &lt;span class=&quot;s1&quot;&gt;&amp;#39;altercation/vim-colors-solarized&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;First, &lt;code&gt;vim-markdown&lt;/code&gt; and &lt;code&gt;vim-pandoc&lt;/code&gt; are extremely powerful extensions for
(you guessed it), &lt;code&gt;markdown&lt;/code&gt; and &lt;code&gt;pandoc&lt;/code&gt;. As I used these for &lt;em&gt;everything&lt;/em&gt;
these days, having good plugins is a requirement. They introduce things like
autocompletion of citations from a &lt;code&gt;bibtex&lt;/code&gt; file, and things like &lt;em&gt;replacing
LaTeX greek letters by the actual greek letter&lt;/em&gt;, which means that when you
are looking at a paragraph, it shows no markup, but the formatting. It’s
really, really amazing when you want to &lt;em&gt;read&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The most recent addition to this collection is &lt;code&gt;vimroom&lt;/code&gt;. This plugins
attempts to replicate the look and feel of &lt;em&gt;WriteRoom&lt;/em&gt;, one of the many, many
“distraction-free” writing softwares. When editing a document, &lt;code&gt;&amp;lt;leader&amp;gt;V&lt;/code&gt;
will center the text on the screen, with ample white-space on each sides,
and remove every piece of clutter from the “interface”. It means that, if
you have a large screen, you don’t need to turn your head all the way to
the left to read what you are working on.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;So that’s it! It’s not much work, and it makes for a really pleasant writing
experience in &lt;code&gt;Vim&lt;/code&gt;. And it’s effortless to switch from “code” to “prose”
mode, making &lt;code&gt;Vim&lt;/code&gt; a very versatile and productive tool.&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>Software papers and open source licenses</title>
     <link href="http://timotheepoisot.fr/2013/12/19/reviewing-software-papers/"/>
    <updated>2013-12-19T00:00:00-05:00</updated>
    <content type="html">&lt;p&gt;I have been reviewing a lot more software / methodological papers these
days, which led me to think about open &lt;em&gt;vs.&lt;/em&gt; closed software (even more
than usual). By &lt;em&gt;closed&lt;/em&gt;, I mean any software that would require me to pay
to be able to reproduce the method, either directly, or through a licence
costing money to the university. Think &lt;em&gt;Mathematica&lt;/em&gt;, &lt;em&gt;matlab&lt;/em&gt;, or any other
commercial tools. Despite what &lt;a href=&quot;http://www.quantumforest.com/2013/12/should-i-reject-a-manuscript-because-the-analyses-werent-done-using-open-source-software/&quot;&gt;some&lt;/a&gt; would have you believe, the way
analyses are done in a “traditional” research paper (&lt;q&gt;Here is my experiment,
here are the analyses I have been doing, and here are my conclusions&lt;/q&gt;)
is an entirely different piece of work. When I review such papers, I care
very little about the software used to obtain the results. And of course,
it’s difficult to reproduce a field survey or a large lab experiment, and
no amount of free software will change that.&lt;/p&gt;

&lt;p&gt;But software papers, &lt;em&gt;i.e.&lt;/em&gt; either papers presenting a new software,
or relying heavily on computer code (&lt;em&gt;i.e.&lt;/em&gt; most simulation studies),
are defined largely by their computability. So let’s jump straight to the
conclusion: would I reject such a paper because the code relies on closed
software? &lt;strong&gt;No&lt;/strong&gt;, for two reasons. The first reason is highly personal:
I would not accept to review it in the first place. My condition to review
a software paper is to be able to understand and evaluate the code, so if
I can’t run the software or understand what it does, I won’t review the
paper. The second reason is that, ultimately, the important thing in a
software paper is the method described, and so as long as I can reproduce
what the authors propose, and it is a useful addition to the methodological
toolkit, there is no reason to reject the paper. An additional reason is that
I am a co-author on at least two (&lt;em&gt;in prep.&lt;/em&gt;) papers using closed software,
and I won’t hold others to a higher standard than the one I hold myself to…&lt;/p&gt;

&lt;p&gt;That being said, there are extremely strong arguments to be made in favor
of using Free and Open-Source Software (FOSS) whenever possible. For one
thing, and although it’s easy to forget that coming from a &lt;em&gt;rich&lt;/em&gt; university,
not everyone can afford to pay a software license. Tools that are relevant
for conservation may be unavailalbe to NGOs if they need to pay to use
them. Even in the academic world, researchers from developing countries,
may have a hard time justifying spending thousands of dollars on software
when there are free alternatives available. My (highly personal) point of
view is that using FOSS software is part of the collective responsibility
to lower the access fee to science.&lt;/p&gt;

&lt;p&gt;Now that we know that &lt;a href=&quot;https://peerj.com/articles/175/&quot;&gt;open data&lt;/a&gt; is associated with an increased
citation rate, I wonder whether the same is true of FOSS-using papers. I
can think a couple reasons for why it should be the case. Describing a new
method is much like explaining a recipe. But I’m much less likely to cook
true &lt;em&gt;crêpes&lt;/em&gt; from Britanny, which require a bulky and expensive &lt;em&gt;billlig&lt;/em&gt;,
than I am to cook the regular version that I can do at home with my frying
pan. Wow, that is a bad metaphor, it almost reads like FOSS is the cheap
knock-off version of science. Never mind… In any case, offering users
a way to apply an analysis at no cost is a good incentive to using your
method. And now that almost anyone knows and uses R (especially students),
you can reach ~100% of your field this way.&lt;/p&gt;

&lt;p&gt;But what should we do when no FOSS software can do the particular analysis
one wants to do? This is a valid and difficult question. It’s obvious
that what matters most is to have the most solid result one can get using
the currently available tools. But on the other hand, contributing new
software is an activity in itself, that is starting to be recognized as
such. Porting a good method into FOSS is probably going to get you some
recognition withing your community. &lt;em&gt;ImpactStory&lt;/em&gt; let you track the impact
of software releases through &lt;em&gt;e.g.&lt;/em&gt; &lt;em&gt;GitHub&lt;/em&gt;. For example, the &lt;em&gt;ImpactStory&lt;/em&gt;
page &lt;a href=&quot;http://impactstory.org/timpoisot/product/puktfnm5rj97v383zwo6smlp&quot;&gt;for the &lt;code&gt;digitize&lt;/code&gt; package&lt;/a&gt; I wrote in one afternoon because I
wanted to know whether it (it: extracting data from published scatterplots)
could be done, show that people found this package useful. While it’s true that
writing useful code is not as appreciated as writing papers that get cited, the
development of new metrics will probably make it increasingly rewarding. And
the less people have to pay, the more likely they are to use your code.&lt;/p&gt;

&lt;p&gt;At the very least, if your code requires proprietary software to run,
pick a &lt;a href=&quot;http://choosealicense.com/&quot;&gt;FOSS license&lt;/a&gt;. There are tools (like &lt;em&gt;Choose a license&lt;/em&gt;,
linked just before) that will allow you to select licenses according to your
needs. Even if people can’t &lt;em&gt;run&lt;/em&gt; the software, they can see how it works,
and translate it in another language it they need it. Starting in January,
all &lt;a href=&quot;http://www.britishecologicalsociety.org/publications/&quot;&gt;BES journals&lt;/a&gt; will require that &lt;em&gt;data&lt;/em&gt; are available, free of
charge and in a repository, when the paper is accepted - and the goal is
clear: allow reprodubilityand re-use. Perhaps the same type of initiatives
should be progressively introduced for code. And this is the part where, as
referees, we can start making a small difference: by suggesting appropriate
FOSS licenses if the authors have not done so. It will help software spread,
and the most methods we have at our disposal, the most likely we have to
find the right one to solve a problem.&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>What's hot on PeerJ?</title>
     <link href="http://timotheepoisot.fr/2013/12/17/what-peerj/"/>
    <updated>2013-12-17T00:00:00-05:00</updated>
    <content type="html">&lt;p&gt;Lat week, I mentionned that ecology is the leading discipline on &lt;a href=&quot;https://peerj.com/preprints/&quot;&gt;&lt;em&gt;PeerJ&lt;/em&gt;
preprints&lt;/a&gt;, as attested by the number of submissions. Which led me to
wondering which topics were actually &lt;em&gt;hot&lt;/em&gt; on the preprint server. &lt;em&gt;PeerJ&lt;/em&gt; do
not have an API, but there URL scheme is not too complicated, and most of the
relevant informations are in the webpage body. So I wrote a very short python
script to get the first 158 preprints, download them, and get the abstract.&lt;/p&gt;

&lt;p&gt;The code goes like this:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;requests&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;bs4&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BeautifulSoup&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;BaseURL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;https://peerj.com/preprints/&amp;quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;StopAt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;158&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;StartAt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Corpus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Fulltext&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preprint_id&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;xrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;StartAt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StopAt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;preprint_page&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BaseURL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;preprint_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;/&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preprint_page&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;status_code&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;preprint_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preprint_page&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;preprint_soup&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BeautifulSoup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;preprint_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;abstract&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preprint_soup&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;meta&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;name&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;description&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;Fulltext&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot; &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;abstract&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;Corpus&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;abstract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fulltext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;There is actually a one-liner version of this code, that exsist solely to
show that you can do horrible twisted things with python. I’m not showing
it. But the point is: this code will return a list of all abstracts, pasted
together in a single sentence. Which I copied, and used in &lt;a href=&quot;http://www.wordle.net&quot;&gt;wordle&lt;/a&gt; to get
the following graphic:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/w-peerj-abs.png&quot; alt=&quot;With abstracts&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So apparently, &lt;code&gt;data&lt;/code&gt; are big, followed by &lt;code&gt;sharks&lt;/code&gt; and &lt;code&gt;whales&lt;/code&gt; (actually
whale sharks), but suriprisingly, there are no big ecological keywords
that are very prominent - which goes well with the idea that &lt;em&gt;PeerJ&lt;/em&gt;
is multi-disciplinary. By changing the &lt;code&gt;BaseURL&lt;/code&gt; variable in my code,
it was easy to get the same picture but for the &lt;em&gt;articles&lt;/em&gt;, &lt;em&gt;i.e.&lt;/em&gt; the
contributions that went through peer-review. According to the front page,
Ecology and Biodiversity are still the leading disciplines there.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/w-peerj-pap.png&quot; alt=&quot;With papers&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It seems to be the case, with &lt;code&gt;species&lt;/code&gt; being the most important word, followed
(still) by &lt;code&gt;data&lt;/code&gt;. Interestingly, clinical and molecular keywords are more
prominent in the published papers than in the preprints. But in any case,
&lt;em&gt;PeerJ&lt;/em&gt; is definitely ecology-friendly, which hopefully will mean that more
and more people will submit there.&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>Data-sharing paper online</title>
     <link href="http://timotheepoisot.fr/2013/12/05/data-sharing-paper/"/>
    <updated>2013-12-05T00:00:00-05:00</updated>
    <content type="html">&lt;p&gt;Our &lt;a href=&quot;http://library.queensu.ca/ojs/index.php/IEE/article/view/4632&quot;&gt;paper&lt;/a&gt; &lt;em&gt;Towards a sustainable ecological science&lt;/em&gt; is now online at
&lt;em&gt;Ideas in Ecology and Evolution&lt;/em&gt;. Thanks are due to Karthik Ram for the
invitation. This is going to be a very exciting special issue. If you want
to know more about the paper, the best thing to do is most likely to read it
(it’s open access). But in short, we (I, Ross Mounce, and Dominique Gravel),
try to make a point of all the benefits of sharing data in ecology. There
are some parts about licenses, and some parts about &lt;code&gt;JSON&lt;/code&gt; (because of course
there are).&lt;/p&gt;

&lt;p&gt;But besides the content of the paper (that made me think &lt;em&gt;a lot&lt;/em&gt; about data
sharing), the way we wrote it was extremely fun. Everything was &lt;a href=&quot;https://github.com/tpoisot/DataSharingPaper/network&quot;&gt;done on
&lt;em&gt;GitHub&lt;/em&gt;&lt;/a&gt;, in &lt;em&gt;mardkwon&lt;/em&gt;,and  we’ve used Issues and all the tricks in
the book to keep track of what needed to be done. It’s also the first paper
in which my twitter handle is listed in the contacts, and I’ll probably do
that for every paper now.&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>Why JSON is my go-to data format</title>
     <link href="http://timotheepoisot.fr/2013/12/02/json-goto-format/"/>
    <updated>2013-12-02T00:00:00-05:00</updated>
    <content type="html">&lt;p&gt;Since this summer, I work with models that generate massive amounts
of output. This weekend batch of simulations resulted in 20+ Gig of raw
data. This particular model outputs very variable data. The number of
lines/columns (were I working in a tabular format) would be unpredictable,
vary across simulations, and generally be a little bit too massive to work
with (simply) in &lt;code&gt;R&lt;/code&gt;. But I’ve been using &lt;code&gt;JSON&lt;/code&gt; for a while now, and it
makes working with these types of data (not the “several Gig” types, the
“highly heterogeneous” type) easy.&lt;/p&gt;

&lt;p&gt;I love &lt;code&gt;JSON&lt;/code&gt; because it can be validated. Running a command like &lt;code&gt;jsonlint
file.json&lt;/code&gt; will either return me the pretty-printed version of the file,
or an error telling me where the file is not conforming to the &lt;code&gt;JSON&lt;/code&gt;
specification. Or in other words, when I read something in memory, I’m
confident it is indeed a correctly formated file.&lt;/p&gt;

&lt;p&gt;But wait, there’s more! In &lt;code&gt;JSON&lt;/code&gt;, you can define &lt;em&gt;schemes&lt;/em&gt;, or a &lt;code&gt;JSON&lt;/code&gt;
file telling you (or a validator) what other &lt;code&gt;JSON&lt;/code&gt; files should look
like. Which means that it’s possible to check that a particular file is
correctly formatted &lt;em&gt;with regard to a previously described data format&lt;/em&gt;. I
use the &lt;code&gt;jsonschema&lt;/code&gt; python module to do that:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;json&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;jsonschema&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;validate&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Read the JSON scheme file&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;scheme.json&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Read the JSON output file&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;output.json&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;op&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Validate&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;validate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;Not valid&amp;quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;Valid&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;And because a&lt;code&gt;JSON&lt;/code&gt; scheme has &lt;a href=&quot;http://json-schema.org/&quot;&gt;field for description of each element&lt;/a&gt;,
your output is essentially self-described. Someone with no prior knowledge
of how you organized your data can take your results, check that they conform
to the specification, and see what each element of the output file represents.&lt;/p&gt;

&lt;p&gt;Although I haven’t bothered to write a scheme (yet), you can see how &lt;code&gt;JSON&lt;/code&gt;
can contain a lot of heterogeneous informations in an easy to read format
&lt;a href=&quot;https://github.com/tpoisot/manna&quot;&gt;on the &lt;code&gt;manna&lt;/code&gt; index page&lt;/a&gt;: the output files give informations about
the species, and for each time steps, the number of individuals, and each
individual interaction.&lt;/p&gt;

&lt;p&gt;While it’s true this information is not extremely complicated, it’s still
simpler to have it in this form, rather than as a text file. But &lt;code&gt;JSON&lt;/code&gt;
truly shines when &lt;em&gt;reading&lt;/em&gt; the data. In the above example, if the &lt;code&gt;op&lt;/code&gt;
object contains a list of species, each having a body size called &lt;code&gt;bs&lt;/code&gt;,
then we can get the mean body size with&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;m_bs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;bs&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sp&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;code&gt;R&lt;/code&gt; can also read &lt;code&gt;JSON&lt;/code&gt; well with the &lt;code&gt;rjson&lt;/code&gt; package. This returns a &lt;code&gt;list&lt;/code&gt;
representation of the &lt;code&gt;JSON&lt;/code&gt; file, so it’s easy to manipulate &lt;code&gt;JSON&lt;/code&gt; objects
with &lt;code&gt;l*ply&lt;/code&gt; functions in &lt;code&gt;plyr&lt;/code&gt;. So now, most of my models work in the same
way. I write one &lt;code&gt;JSON&lt;/code&gt; file for each simulation (or variations thereof)
into an &lt;code&gt;output&lt;/code&gt; folder. Then I read through each file with &lt;code&gt;python&lt;/code&gt; and/or
&lt;code&gt;R&lt;/code&gt;, and I have a great time doing it!&lt;/p&gt;

&lt;p&gt;The main drawback of &lt;code&gt;JSON&lt;/code&gt; (&lt;a href=&quot;http://www.alcides-mp.com/?p=1&quot;&gt;as pointed out here&lt;/a&gt; are that it must be
read in memory entirely before it’s used (and it gets parsed at this time
too). Or in other words, it can be slow. But it’s a good thing! I found out
that it forces me to (i) aim for the most concise representation possible,
and (ii) split the output in chunks when needed. These chunks can be read
in parallel later, and re-assembled, so I don’t try to load files of a few
hundreds Mb at times.&lt;/p&gt;

&lt;p&gt;So now, go try &lt;code&gt;JSON&lt;/code&gt; for yourself. In the &lt;code&gt;manna&lt;/code&gt; program linked above, there
are examples with (admittedly badly written) &lt;code&gt;R&lt;/code&gt; files to read and manipulate
&lt;code&gt;JSON&lt;/code&gt; outputs. And keep in mind that when you’ll be coming back to your
output files in six months, you’ll be glad to have a verbose format and a
scheme describing it to understand what is going on…!&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>The pros and cons of using R packages for teaching</title>
     <link href="http://timotheepoisot.fr/2013/11/27/r-packages-teaching/"/>
    <updated>2013-11-27T00:00:00-05:00</updated>
    <content type="html">&lt;p&gt;R packages are one of the best tools we have. It’s a library of 1000s
of functions ready to be used, all wrapped in a single common language,
and it’s free. I wrote some, and used even more. When I review a paper,
upon seeing “we used function &lt;code&gt;x&lt;/code&gt; in the version 2.3 of package &lt;code&gt;y&lt;/code&gt;”,
I know a lot about what the authors have been doing (and I can check the
help of this function for references and additional details). And obviously,
training students about which packages are widely used in a particular field
is an important task, because it will ensure that they will speak the same
language as other scientists in the field.&lt;/p&gt;

&lt;p&gt;Because packages (often) represent the &lt;em&gt;state of the art&lt;/em&gt; in a particular
field, or because they offer a unified interface to a lot of different methods
(&lt;code&gt;simecol&lt;/code&gt; is a good example of that), it’s important that students know how
to use them (and most importantly, which packages to use). To some extent,
packages are just another tool, like PCR or statistics. Knowing how to use
them (properly) saves time, and opens new possibilities for analyses. And
let’s just be realistic, everyone uses packages. All the time. So yes, of
course, the students should be familiar with the most important in their field.&lt;/p&gt;

&lt;p&gt;An important point is that we also start to see the development of &lt;em&gt;package
ecosystems&lt;/em&gt;. The &lt;a href=&quot;http://ropensci.org/packages/index.html&quot;&gt;&lt;em&gt;rOpenSci&lt;/em&gt;&lt;/a&gt; project is an example of that. They propose a
lot of different packages whose common purpose is to interact with databases
and API for science, but the real power is offered by the ability to integrate
several of these packages &lt;a href=&quot;http://ropensci.org/usecases/index.html&quot;&gt;in a single analysis&lt;/a&gt;. Want to get the list of
species in a country, and check which are invasive, then plot that onto
their phylogenetic tree? It can be done. Another well known example is the
&lt;code&gt;plyr&lt;/code&gt;/&lt;code&gt;reshape2&lt;/code&gt;/&lt;code&gt;ggplot2&lt;/code&gt; combo, which is (seriously) the only reason I
still have to start &lt;code&gt;R&lt;/code&gt; at least once a day.&lt;/p&gt;

&lt;p&gt;So on one hand, packages are really good, because they save time and
allow to do an analysis which (hopefully) conforms with the current set of
“best practices” in the field. On the other hand, when you start working
&lt;em&gt;only&lt;/em&gt; with what the packages have to offer, you can severely limit your
creativity. There are questions that will require new code to be written,
and you’ll most likely hit obstacles along the ways. That, too, should be
something the students encounter during their training.&lt;/p&gt;

&lt;p&gt;And this is when the limits of &lt;code&gt;R&lt;/code&gt; start to show. As John Cook said (&lt;a href=&quot;http://readwrite.com/2013/11/25/python-displacing-r-as-the-programming-language-for-data-science&quot;&gt;source&lt;/a&gt;),
“I find it more helpful to think of R as having a programming language than
being a programming language”. I would never have put that so eloquently,
and it is entirely ture. Over the last two months, I gave a graduate training
class on &lt;em&gt;Algorithms and programming for environmental sciences&lt;/em&gt;, in which
I tried to discuss how to make “good” (robust, user-friendly, stupid-proof)
programs. Regardless of what the students learned, I definitely realized
that &lt;code&gt;R&lt;/code&gt; is a &lt;em&gt;huge mess&lt;/em&gt; when you try to work outside of packages, or
do something else than statistics. Interestingly, even Hadley Whickam’s
forthcoming &lt;a href=&quot;http://adv-r.had.co.nz/&quot;&gt;&lt;em&gt;Advanced R development&lt;/em&gt;&lt;/a&gt; starts by saying that it will
show how &lt;em&gt;what seems horrible is merely “not that bad”&lt;/em&gt; (go read the book,
by the way, it’s great). And so understanding &lt;em&gt;what&lt;/em&gt; to do often comes second
to understanding &lt;em&gt;how to do it&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The (many, many) quirks of &lt;code&gt;R&lt;/code&gt; nonwithstanding, working with a package
and doing something new are two different approaches. The former involves
looking at the examples, and reading the documentatin to see what each
function does. The later requires a working knowledge of the language, and
some notions of algorithmic. Yet, judging from my observations, these two
different exercices are often (and let’s not forget statistics) presented
together, under the general denomination of &lt;code&gt;R&lt;/code&gt;. And when, afterwards, students
complain of “not getting &lt;code&gt;R&lt;/code&gt;”, it’s hard to tell whether what they don’t
get is what exactly a &lt;code&gt;while&lt;/code&gt; loop does (which is not a &lt;code&gt;R&lt;/code&gt;-specific issue),
or why a &lt;code&gt;data.frame&lt;/code&gt; is also a &lt;code&gt;list&lt;/code&gt; and a &lt;code&gt;matrix&lt;/code&gt; (which is a reasonable
question, and quite specific to &lt;code&gt;R&lt;/code&gt;); you may know how to do statistics with
&lt;code&gt;R&lt;/code&gt;, or use &lt;code&gt;vegan&lt;/code&gt; or &lt;code&gt;picante&lt;/code&gt;, but not know &lt;code&gt;R&lt;/code&gt; (or the other way around).&lt;/p&gt;

&lt;p&gt;The point I’m slowly getting at is that you’ll most likely end up in a
situation which is not covered by &lt;em&gt;any&lt;/em&gt; package available. Or, as a student,
you’ll have to modify a code for a group project, which means re-writing
some functions, or changing the data structure. Part of the training should
prepare students to do this kind of things. Rather than using a pre-made
function to calculate a Shannon’s index, or even find the maximal value in
an array, let’s walk students through the writing of this function.&lt;/p&gt;

&lt;p&gt;So, to conclude, while it’s clear that I have a love/hate relationship
with &lt;code&gt;R&lt;/code&gt;, I think it’s still an invaluable tool for teaching, especially in
undergraduate courses. &lt;code&gt;python&lt;/code&gt; might be as easy and more coherent, but less
people use it (for now…), and &lt;code&gt;R&lt;/code&gt; is still the &lt;em&gt;lingua franca&lt;/em&gt;. And a part
of the success of &lt;code&gt;R&lt;/code&gt; is the diversity of available packages. But relying
only on packages creates this weird black box situation, in which students
will know what the function does, but not necessarily &lt;em&gt;how&lt;/em&gt; it does it; and
knowing how stuff works is key when you have to create your own stuff. So
&lt;strong&gt;pros&lt;/strong&gt;, packages are awesome because 90% of what you want to do is already
programmed. &lt;strong&gt;Cons&lt;/strong&gt;, the remaining 10% will be extremely hard for you to
get if you don’t get your hands dirty once in a while, and write things
from scratch.&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>Spatially explicit metapopulation model in R</title>
     <link href="http://timotheepoisot.fr/2013/11/25/metapopulation-model-r/"/>
    <updated>2013-11-25T00:00:00-05:00</updated>
    <content type="html">&lt;p&gt;One of my favorite tools to work with networks is &lt;a href=&quot;http://networkx.github.io/&quot;&gt;the &lt;code&gt;networkx&lt;/code&gt; python
package&lt;/a&gt; (if only because lists comprehensions make so much sense when you
work with graphs). But for teaching purposes (especially in ecology), having
purely &lt;code&gt;R&lt;/code&gt;-based tools is better. The students know the language (at least
enough to get around most problems in a few hours, and so they can focus on
the theory rather than the tedious details of implementation. So I started
looking for good graph analysis tools in R.&lt;/p&gt;

&lt;p&gt;I’ve read good thing (well, &lt;a href=&quot;http://assemblingnetwork.wordpress.com/tutorials/network-basics/&quot;&gt;good-looking code&lt;/a&gt;, actually) about the
&lt;code&gt;igraph&lt;/code&gt; package, so I decided to try it (good surprise: there are both &lt;code&gt;R&lt;/code&gt;,
&lt;code&gt;python&lt;/code&gt; and &lt;code&gt;C&lt;/code&gt; implementations. My first two projects when I’m doing graph
things are (i) how fast can I implement Williams &amp;amp; Martinez &lt;em&gt;niche model&lt;/em&gt;, and
(ii) how fast can I implement a spatially explicit metapopulation model. I have
folders in my computers with various versions of both in various languages.&lt;/p&gt;

&lt;p&gt;So I decided to work on the later project. The idea is to use &lt;code&gt;igraph&lt;/code&gt; to
generate a random geometric graph, and use that as the landscape over which the
metapopulation is simulated. The code is &lt;a href=&quot;https://gist.github.com/tpoisot/7547954&quot;&gt;available as a gist&lt;/a&gt;. Coming
from &lt;code&gt;networkx&lt;/code&gt;, it took some time getting used to the different approach. But
overall, &lt;code&gt;igraph&lt;/code&gt; convinced me, and I’ll most definitely use it when teaching
about networks in the future.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/rmetapop.png&quot; alt=&quot;Metapopulation mode&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As a side note, the code allows to generate 3D spatial graphs. It’s entirely
useless, but it’s kinda cool!&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>Collaborating with markdown and bibtex</title>
     <link href="http://timotheepoisot.fr/2013/11/10/shared-bibtex-file-markdown/"/>
    <updated>2013-11-10T00:00:00-05:00</updated>
    <content type="html">&lt;p&gt;The single most annoying issue when using &lt;code&gt;pandoc&lt;/code&gt; to work collaboratively on
papers is that it might be difficult for other people to compile the paper if
they do not use your bibtex file. And if there is ony thing I avoid like the
plague, it’s having several bibtex files all over the place. And I’m can’t
be bothered to keep “Collections” or separate folders in Zotero. So clearly,
I had to code my way out of this one.&lt;/p&gt;

&lt;p&gt;The good thing of using &lt;code&gt;pandoc&lt;/code&gt; is that the citation syntax is remarkably
simple: &lt;code&gt;@key&lt;/code&gt;. It means that using a simple &lt;code&gt;grep&lt;/code&gt; command&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;grep @&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;-:_a-zA-Z0-9&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;* ms.md -oh --color&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;never | sort  | uniq -u | sed &lt;span class=&quot;s1&quot;&gt;&amp;#39;s/@//g&amp;#39;&lt;/span&gt; &amp;gt; bib.keys
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;, I can generate &lt;code&gt;bib.keys&lt;/code&gt;, a list with all the keys encountered in
&lt;code&gt;ms.md&lt;/code&gt;. The keys will be present only once, and sorted. The first few lines
of one such file are&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text&quot;&gt;allesina_competitive_2011
angilletta_temperature_2004
araujo_using_2011
baiser_geographic_2012
baskerville_spatial_2011
bluthgen_what_2008
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, I need to take each of these keys, read my big &lt;code&gt;library.bib&lt;/code&gt; file, and
extract only the entries that are cited in the document. So I installed a
&lt;a href=&quot;https://github.com/sciunto/python-bibtexparser&quot;&gt;bibtex parser for python&lt;/a&gt;, and started doing exactly that. The amazing
thing is, this only takes four (interesting) lines:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;## Step 1 - read the key list&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rstrip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kl&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;## Step 2 - read the library file&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;refs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BibTexParser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bib_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_entry_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;## Step 3 - extract the used entries&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;used_refs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;refs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iteritems&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;## Step 4 - convert the dicts back into bibtex&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;refs_as_bib&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dict2bib&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;used_refs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iteritems&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uk&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uk&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uk&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;used_refs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()]&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;## Step 5 - write the output file&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;codecs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;utf-8-sig&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;writelines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;refs_as_bib&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This code will print a list of all the keys in the &lt;code&gt;bib.keys&lt;/code&gt; that have
&lt;em&gt;not&lt;/em&gt; been matched to an entry in the main library file. If all went well,
this list should be empty. I’ve uploaded the whole file as a &lt;a href=&quot;https://gist.github.com/tpoisot/7406955&quot;&gt;gist&lt;/a&gt;, if you
intend to use it.&lt;/p&gt;

&lt;p&gt;And of course, you can nicely wrap things up in a &lt;code&gt;makefile&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;makefile&quot;&gt;&lt;span class=&quot;nv&quot;&gt;python&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; python2
&lt;span class=&quot;nv&quot;&gt;refs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; refs.bib
&lt;span class=&quot;nv&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; ms.md
&lt;span class=&quot;nv&quot;&gt;library&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; /path/to/main/bibtex/file.bib

&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;refs&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;: bib.keys
   &lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;python&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt; extractbib.py bib.keys &lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;library&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;refs&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;

bib.keys: 
   grep @&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;-:_a-zA-Z0-9&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;* &lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;text&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt; -oh --color&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;never | sort  | uniq -u | sed &lt;span class=&quot;s1&quot;&gt;&amp;#39;s/@//g&amp;#39;&lt;/span&gt; &amp;gt; bib.keys
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I’m glad that I finally have a solution to this problem. Of course, a
multi-author version is not difficult to do (just have each author write
its own bibtex file, and put them all together before running &lt;code&gt;pandoc&lt;/code&gt;). It
also means that my &lt;code&gt;pandoc&lt;/code&gt;-using papers are going to finally be entirely
reproducible, as I’ll distribute the references list in the &lt;em&gt;github&lt;/em&gt;
repository.&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>Notes on test-driven development (in Python)</title>
     <link href="http://timotheepoisot.fr/2013/11/04/test-driven-python/"/>
    <updated>2013-11-04T00:00:00-05:00</updated>
    <content type="html">&lt;p&gt;I’m looking into the methodology of &lt;em&gt;test-driven development&lt;/em&gt;, that is when
you write your tests &lt;em&gt;before&lt;/em&gt; writing your code. The advertised benefit is
that you know in advance the behavior of your code, and it will make it easier
to implement and debug. This &lt;a href=&quot;http://www.onlamp.com/pub/a/python/2004/12/02/tdd_pyunit.html&quot;&gt;paper at O’Reilly&lt;/a&gt; is a good introduction
(although the exact functions of &lt;code&gt;unittest&lt;/code&gt; it uses are now deprecated). To
get started, I’ll work on a simple script that takes a series of numerical
values, and divide them by their max, to get the equivalent series of values
but in [0;1]. Let’s start with the basics:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;unittest&lt;/span&gt;     &lt;span class=&quot;c&quot;&gt;# for testing&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# for other things&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The first function I’d like to write will be called &lt;code&gt;scale&lt;/code&gt;, and it will take a
(&lt;code&gt;numpy&lt;/code&gt;) array of numerical values, and return the same array divided by its
maximal value. So my first &lt;em&gt;unit test&lt;/em&gt; will test that the function performs
as needed:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;scaleTest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unittest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TextCase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;testOnKnownResult&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;KnownInput&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;Scaled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;KnownInput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;assertTrue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Scaled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Scaled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;There are a number of stupid-proofing steps required. First, the function
cannot work when all values in the array are 0, or if there are negative
values, so I’ll write a test for that. I want the function &lt;code&gt;scale&lt;/code&gt; to raise a
&lt;code&gt;ValueError&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;testNegative&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;WithNeg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
   &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;assertRaises&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ne&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;WithNeg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;testNull&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;OnlyNull&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
   &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;assertRaises&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ne&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OnlyNull&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now I have one test to check that the expected behavior is indeed obtained,
and two tests to check that the input values are correct. Things are starting
to look good! The one final thing that I want to enforce is the type of
inputs. Specifically, I want &lt;code&gt;numpy&lt;/code&gt; arrays of numeric types. If this is
not the case, the &lt;code&gt;scale&lt;/code&gt; function will raise a &lt;code&gt;TypeError&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;testType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;WithChar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;0.0&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
   &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;assertRaises&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ne&quot;&gt;TypeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;WithCar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;At this point, even though I haven’t yet wrote a single line of the &lt;code&gt;scale&lt;/code&gt;
function, I know quite well how it should work! Importantly, I know the
type of data that will come in this function. This is something I like when
writing code: I need to understand which data go where, and how they are
formatted and transformed along the way. I try to make students think about
this when giving courses. What kind of data go in? What kind of data come
out? This approach forces to determine when and how the function will break,
and it’s great to have a very clear idea of the data types.&lt;/p&gt;

&lt;p&gt;Now is the time to program the actual function. It will take one argument,
and return another array (the original one is not modified). Let’s write
the simplest possible form of this function:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In most situations, I would have been happy writing the function this way. Let’s integrate it with the test suite, and see how it goes:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;#! /usr/bin/python2&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;unittest&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;## scaleTest goes here&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;## scale goes here&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;unittest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here is the output of running this file:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text&quot;&gt;======================================================================
FAIL: testNegative (__main__.scaleTest)
----------------------------------------------------------------------
Traceback (most recent call last):
File &amp;quot;lv.py&amp;quot;, line 21, in testNegative
self.assertRaises(ValueError, scale, WithNeg)
AssertionError: ValueError not raised
======================================================================
FAIL: testNull (__main__.scaleTest)
----------------------------------------------------------------------
Traceback (most recent call last):
File &amp;quot;lv.py&amp;quot;, line 18, in testNull
self.assertRaises(ValueError, scale, WithNeg)
AssertionError: ValueError not raised
----------------------------------------------------------------------
Ran 4 tests in 0.001s
FAILED (failures=2)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;There are &lt;em&gt;only&lt;/em&gt; two failed tests. This is because &lt;code&gt;testOnKnownResult&lt;/code&gt; is
expected to succeed, and &lt;code&gt;testType&lt;/code&gt; will catch the &lt;code&gt;TypeError&lt;/code&gt; raised by
&lt;code&gt;np.max&lt;/code&gt; if there are arguments of the bad type. So now I just need to test
that the argument are not negative, or not only zeroes:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   &lt;span class=&quot;c&quot;&gt;# We test that values are positive&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;ne&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;Values of p cannot be smaller than 0&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
   &lt;span class=&quot;c&quot;&gt;# We test that values are not all null&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;ne&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;Values of p cannot be all equal to 0&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
   &lt;span class=&quot;c&quot;&gt;# Finally we return the result&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;With these two checks, we can now re-run the tests:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text&quot;&gt;....
----------------------------------------------------------------------
Ran 4 tests in 0.001s
OK
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Mission accomplished! It requires some discipline to work this way, but I
actually enjoyed going through this example. I really like the fact that
this approach forces to ask question about the structure of the code first,
and write the actual code later.&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>Why should Ecology be open?</title>
     <link href="http://timotheepoisot.fr/2013/11/03/open-ecology/"/>
    <updated>2013-11-03T00:00:00-04:00</updated>
    <content type="html">&lt;p&gt;There are a lot of extremely good arguments to defend the fact that &lt;a href=&quot;http://www.technology.org/2013/10/04/science-even-open/&quot;&gt;&lt;em&gt;Science&lt;/em&gt;
(as a whole) should be more open&lt;/a&gt;. To summarize them very roughly: it’s the
ethical thing to do as it allows everyone to access information, it’s easier
for scientists to access information, it’s faster than the traditional
peer-review system when you need to get your work noticed, and it’s &lt;em&gt;much less
expensive&lt;/em&gt; than closed-source science. I could also elaborate on transparency,
accountability, and the refusal to put a wall around knowledge for a while
as well. In short, I’m yet to find an argument that would convince me that
open science is a bad thing.&lt;/p&gt;

&lt;p&gt;What we call &lt;em&gt;open science&lt;/em&gt; obviously varies from people to people, but the
common thread is that it is a &lt;em&gt;set of practices aiming a lowering the
technological, financial, and legal barrier to the accessibility of scientific
materials, methods, processes, and outputs&lt;/em&gt;. This includes a diversity of
practices such as open manuscript writing, the use of preprints, data sharing,
in addition to open access publishing and the use of free/open source
software. Most of these practices can be applied to nearly all fields
of science, as proven by the &lt;a href=&quot;http://openwetware.org/wiki/Main_Page&quot;&gt;&lt;em&gt;OpenWetWare&lt;/em&gt; wiki&lt;/a&gt;, that caters
specifically to experimental biology and biochemistry.&lt;/p&gt;

&lt;p&gt;An interesting question that keeps popping up whenever I discuss &lt;em&gt;Open
ecology&lt;/em&gt;, or &lt;em&gt;Open biodiversity&lt;/em&gt;, is “Why should it be different in ecology?”.
Or expressed in another way, why should ecology pose particular challenges as
far as open science is concerned? It is a very valid question, and in
preparation for the &lt;em&gt;Open biodiversity&lt;/em&gt; panel that will take place at the QCBS
meeting in a month and a half, I thought it was time to bring some elements to
answer it.&lt;/p&gt;

&lt;p&gt;Let’s start by recognizing that there are (broadly) two types of ecologists.
The “empirical” ecologists (including the microcosm people) rely on empirical
observations, and extensive field surveys, to address their questions. The
“theoretical” ecologists, on the other hand, integrate different data sources,
or build models, to understand “general” questions. There are obviously
people working all along this continuum (I don’t consider myself a “pure”
theoretician, for example), and empiricists contributing some of the
most important ecological &lt;em&gt;theories&lt;/em&gt;, but we can all agree that leaning
towards one end of the continuum implies having a different set of
practices. And to make things worse, the communication between the two
groups is not as good as it should. While it’s easy (I would like to say
&lt;em&gt;natural&lt;/em&gt;) for theoreticians to have an entirely open workflow (put
your code on &lt;em&gt;GitHub&lt;/em&gt;, use it to write your manuscripts, push your
data on &lt;em&gt;figshare&lt;/em&gt; using the API, and &lt;em&gt;voilà!&lt;/em&gt;), it’s slightly more
complicated for empiricists. While it’s true that anyone can make data
public, you can’t reasonably release your field site under a &lt;em&gt;Creative
Commons&lt;/em&gt; licence (because it doesn’t make any sense…).&lt;/p&gt;

&lt;p&gt;There are two points at which both worlds meet, however: data and algorithms.
Even for the most local and system-centered question, there is a large quantity
of required data. And because data are essentially multivariate, sometimes
incomplete, collected with unbalanced designs, and generally subject to the
contingencies of the &lt;a href=&quot;http://dna-protein.blogspot.com/2012/03/harvard-law-of-biology.html&quot;&gt;Harvard Law of Biology&lt;/a&gt;, these is often a need for
elegant (read: complicated) numerical methods to make sense of them (but this
is easy to solve, code should always be made open source, in
non-proprietary languages). This is probably the unique challenge of
&lt;em&gt;open ecology&lt;/em&gt;: we produce a lot of data, we need a lot of data, but there are
so many peculiarities attached to datasets that sharing them is by nature
a difficult task. Molecular biologists do not have this problem. The &lt;code&gt;fasta&lt;/code&gt;
format is simple because the biological reality of what it represents
(sequences) is simple too (or at least, it is easy to represent the building
blocks). And so it seems almost natural than sequences databases are so
prominent: there is no obstacle to data sharing because anyone can use
a &lt;code&gt;fasta&lt;/code&gt; file after two minutes of explanation of the format. I cannot remember
a single case when I managed to become entirely comfortable with the structure
of an Excel file in less than an afternoon.&lt;/p&gt;

&lt;p&gt;Open ecology will probably be much like all other forms of open science, but
the data heterogeneity challenge is especially problematic. There are certain
ways to solve it, though.&lt;/p&gt;

&lt;p&gt;First, we need &lt;strong&gt;strict data specifications&lt;/strong&gt;. If several groups work on the
same questions in similar systems, it would make sense that the data are
formatted in a common way. A good opportunity to draft these specifications is
large working groups, in which people sharing a common interest would think
about the “core” and “satellite” properties of a dataset. This will also
speed-up the development of data repositories with APIs. My personal favorite
for the development of data specifications is &lt;code&gt;JSON&lt;/code&gt; schemes, but really any
kind will do. Data are highly structured information, and it makes sense that
they are used and shared in a highly structured way. It is quite obvious that
there will not a be a single &lt;em&gt;ecological ontology&lt;/em&gt;, but if we managed to get it
right for a few dozens of high quality ones, it will be a strong enhancement
over the current data format of “However I felt that day” (I’m guilty of this
one, of course).&lt;/p&gt;

&lt;p&gt;Second, we need &lt;strong&gt;stricter data review&lt;/strong&gt;. Once the data specification has been
published, it is important that its use is enforced by referees and editors, so
as to make sure that data will be re-usable. This is different from evaluating
the quality of data (data quality is only measurable in the light of the
specific question they are used for). What I have in mind is more along
the lines of a checklist with a few points: is the data conforming to the
specification (this step can be automated with a &lt;code&gt;jsonlint&lt;/code&gt;-like tool), is the
data easy to access, and are enough data released to make the dataset re-usable?&lt;/p&gt;

&lt;p&gt;Third, and finally, we need to &lt;strong&gt;un-install Excel and similar software&lt;/strong&gt;. What
we need instead, is a &lt;code&gt;pandoc&lt;/code&gt; for data. &lt;code&gt;pandoc&lt;/code&gt; is a tool to convert text
formats into other text formats. It’s awesome. And with strict data
specifications, we should be able to write one for ecology. This will allow use
to store data in their correct format (&lt;em&gt;i.e.&lt;/em&gt;, conforming to the data
specification), but use them in another format when we need them in
another format.&lt;/p&gt;

&lt;p&gt;All of this will require a fair amount of community coordination, and changes
in the training and teaching of ecologists, but it’s all for the greater good.
Some outstanding ecological problems will only be solved when a critical mass
of data is reached, and it would be extremely disappointing to realize that
these data were existing, but not available due to poor practices. So in short,
this is the challenge specific to open ecology: &lt;strong&gt;making sense of highly
heterogeneous and local data, and mobilizing them to address global and
general questions&lt;/strong&gt;.&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>The (French) paradox of Closed Open Access</title>
     <link href="http://timotheepoisot.fr/2013/11/02/my-science-work/"/>
    <updated>2013-11-02T00:00:00-04:00</updated>
    <content type="html">&lt;p&gt;The OpenAccessWeek in France generated a &lt;em&gt;huge&lt;/em&gt; backlash, mostly owing to the
identity of the organizer. This edition was organized by the for profit
“scientific social network” &lt;em&gt;MyScienceWork&lt;/em&gt; (I’m not going to link them). &lt;em&gt;My
Science Work&lt;/em&gt; (&lt;em&gt;MSW&lt;/em&gt; henceforth) is a social network in which people can…
well, you know what a social network is. This one is yet another social network
for scientists, much like Academia.edu and ResearchGate. I don’t care all that
much about these tools.&lt;/p&gt;

&lt;p&gt;Let’s summarize the situation. The French OpenAccesWeek was organized by &lt;em&gt;My
Science Work&lt;/em&gt;, and got backed up by several public organisms involved in
research: some labs, some universities, other related institutions. During this
operation, the credibility of &lt;em&gt;MSW&lt;/em&gt; got a huge boost in the French OA
community, in large part because of the fact that high-profile institutions
lent their credibility to the OpenAccessWeek.&lt;/p&gt;

&lt;p&gt;During the OpenAccessWeek itself, the critics started to emerge. &lt;a href=&quot;http://translate.google.com/translate?hl=fr&amp;amp;sl=fr&amp;amp;tl=en&amp;amp;u=http%3A%2F%2Fblog.stephanepouyllau.org%2F709&quot;&gt;Stéphane
Pouyllau &lt;/a&gt; started talking about &lt;em&gt;private open access&lt;/em&gt;. Shortly
thereafter, &lt;a href=&quot;http://translate.google.com/translate?hl=fr&amp;amp;sl=fr&amp;amp;tl=en&amp;amp;u=http%3A%2F%2Fpenserclasser.wordpress.com%2F2013%2F11%2F02%2Fopenaccessweek_france%2F&quot;&gt;Elifsu Sabuncu&lt;/a&gt; produced a great synthesis of the most important
reactions on twitter and in blogs (both links are through Google translate,
which gives a fairly broken but acceptable translation). What are these
critics about?&lt;/p&gt;

&lt;p&gt;Well, for a “Frontrunner in Open Access”, &lt;em&gt;MSW&lt;/em&gt; is surprisingly closed. Their
website lists over 28 millions academic papers in Open Access. I tried to
access some of mine, and when I clicked on the “Download link”, I got
redirected to a login/signup page. Does it seems like a &lt;em&gt;huge&lt;/em&gt; problem to you?
Because it is. When you put papers behind a wall, you are not advancing Open
Access. You are using the OA label to advance your business, and you are not
more worthy than a predatory OA publisher. If your goal is to provide a service
to the scientists, let us download the papers without signing-up for yet
another website we’ll never visit again. &lt;/p&gt;

&lt;p&gt;And it’s not like the links to the original publications is easy to spot,
either. It’s nowhere to be found on the pages. You have no choice but to
signup for their “service”, if you want to get access to the paper (or,
well, you can realize that this is bullshit and go find the PDF
somewhere else). When some authors took offense with the practice,
the heads of &lt;em&gt;MSW&lt;/em&gt; proposed to remove their articles from the platform.
They were also quite active in insulting some of the most vocal critics on
their blogs, which is not a smart move. So it seems that &lt;em&gt;MSW&lt;/em&gt; has no will
to change their system, and is instead trying to silence the critics (you
cannot silence French people - criticism is an &lt;em&gt;art de vivre&lt;/em&gt; for
us!).&lt;/p&gt;

&lt;p&gt;If it were just yet another social network for scientists, I’m sure no one
would have cared about their “signup-required” policy. But &lt;em&gt;MSW&lt;/em&gt; was, for
a week, the face of French Open Access. The closed, greedy, critics-insulting
face of French Open Access. So here is your explanation of the huge backslash.
People advocating &lt;em&gt;open&lt;/em&gt; access took it badly when a business tried to trick
people into thinking they were advancing OA, but was instead freeloading on OA
initiatives to make money. This is extremely worrisome. Predatory publishing is
bad press enough for OA, we really don’t need new forms of predation.&lt;/p&gt;

&lt;p&gt;And the next step, after the name calling and the finger pointing will have
ended, is to have a good productive debate about &lt;em&gt;open&lt;/em&gt; access. Access is not
&lt;em&gt;open&lt;/em&gt; if you have to pay for it. And the fact that the price you pay for
a paper at &lt;em&gt;MSW&lt;/em&gt; is not monetary makes no matter: you pay with your
information, with your facebook profile, with your email address. When every
piece of information about you can be turned into a profit, &lt;strong&gt;every wall is
a paywall&lt;/strong&gt;. Parasitic behaviors, in which some use the OA label to get
credibility, but exploit OA to increase their userbase and their profit, must
be denounced &lt;em&gt;en masse&lt;/em&gt; by the community. And just for this reason, even so I’m
disappointed that the Open Access Week was organized by &lt;em&gt;MSW&lt;/em&gt;, I’m glad to see
that there is such a massive discussion about the ethics of putting OA papers
behind (pay)walls.&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>Mapping ecological concepts using twitter</title>
     <link href="http://timotheepoisot.fr/2013/10/18/mapping-ecological-concepts/"/>
    <updated>2013-10-18T00:00:00-04:00</updated>
    <content type="html">&lt;p&gt;I’ve been setting up a Twitter account for the &lt;a href=&quot;http://twitter.com/sfecologie/&quot;&gt;French Ecological
Society&lt;/a&gt;, and while we currently use it as a tool to relay the various
informations we want to share, it’s also a great way to engage with people. So
the question that immediately came to mind is: what kind of topics are
associated with ecology on twitter? My own twitter list is a poor indicator of
the “general public” as far as ecology is concerned, so I had to look for
another solution.&lt;/p&gt;

&lt;p&gt;Twitter offers a series of &lt;em&gt;Streaming API&lt;/em&gt;, which allows to “listen” to the
conversation, by tracking some keywords, or users, or geographic location. So
I downloaded the excellent &lt;a href=&quot;https://github.com/geduldig/TwitterAPI&quot;&gt;&lt;code&gt;TwitterAPI&lt;/code&gt; &lt;/a&gt; module for &lt;code&gt;python&lt;/code&gt;, and
tracked a series of keywords. After some trial and error, I settled on
&lt;code&gt;biodiversity&lt;/code&gt;, &lt;code&gt;biological diversity&lt;/code&gt;, &lt;code&gt;ecology&lt;/code&gt;, &lt;code&gt;species richness&lt;/code&gt;,
&lt;code&gt;ecosystem services&lt;/code&gt;, &lt;code&gt;ecosystem functioning&lt;/code&gt;, and &lt;code&gt;ecological&lt;/code&gt;. I left out
&lt;code&gt;conservation&lt;/code&gt; and &lt;code&gt;ecosystem&lt;/code&gt;, because they had a really high rate of false
positives (in engineering and software, respectively).&lt;/p&gt;

&lt;p&gt;The streaming API, in a nutshell, will return a new line everytime a tweet that
matches the search parameters is posted. Not all tweets are sampled, but it’s
approximately a random sampling, so more than good enough for a side-project.
I left the script running for a few hours at a time, which gave me a database
of over 1000 tweets, about 600 of which were retained. I’ve removed all tweets
using a alphabet that is not latin, and there were quite a bit of these.&lt;/p&gt;

&lt;p&gt;Once this was done, I just read each line in &lt;code&gt;python&lt;/code&gt; (the Twitter API have the
good taste of returning everything as &lt;code&gt;json&lt;/code&gt; strings), selected the text,
and cleaned it. I simple (i) converted everything to lower case, (ii)
removed every non-ascii characters, (iii) removed punctuations, and (iv)
removed the hasthag (&lt;code&gt;#&lt;/code&gt;) symbol. Then I extracted all of the unique words
in each tweet, and let the fun begin!&lt;/p&gt;

&lt;p&gt;One of the things I know how to do is network analysis. So I settled on the
following procedure to find connections between words. All of the unique words
are nodes in a network, and two nodes are connected whenever they appear in the
same tweet. That makes for a &lt;em&gt;lot&lt;/em&gt; of connections, but it’s not a problem
because I will eliminate a lot of them later. At this stage, I have a network
with 2600 nodes, and over 30000 undirected edges. Obviously (i) words appearing
only once in the dataset have little interest, and (ii) words like &lt;code&gt;the&lt;/code&gt; and
&lt;code&gt;in&lt;/code&gt; have a much higher chance of being in the same tweet than &lt;code&gt;amazonia&lt;/code&gt; and
&lt;code&gt;tits&lt;/code&gt; (I checked the original tweet, and it was not about ornithology).&lt;/p&gt;

&lt;p&gt;Before I go into how I accounted for that, some additional cleaning steps: all
usernames (&lt;code&gt;@&lt;/code&gt;), urls (&lt;code&gt;htt&lt;/code&gt;), and twitter-specific idioms (&lt;code&gt;RT&lt;/code&gt;, &lt;code&gt;MT&lt;/code&gt;, &lt;code&gt;ff&lt;/code&gt;)
were excluded. I also deleted all of the small connex components (&lt;em&gt;i.e.&lt;/em&gt;
small groups of words that were not connected with the rest of the
dataset). Then, the most arbitrary part of the work began. I removed
&lt;em&gt;all&lt;/em&gt; the nodes with a betweenness centrality of 0. The betweenness
centrality is the frequency at which a node appears in the shortest paths of
the graph, so I assumed that words that were not part of the shortest
connexions were not really important. Most of the words were excluded using
this proccess, and the network felt to a much more manageable 149 nodes and
2509 edges.&lt;/p&gt;

&lt;p&gt;Part of these were still words like &lt;code&gt;the&lt;/code&gt;, &lt;code&gt;at&lt;/code&gt;, and so forth. I’ll eventually
use TF-IDF to select relevant words from each tweet, but remember, this is
a quick-and-dirty analysis. So I simply looked at mylist of nodes, and removed
every words that were not relevant (this is rather arbitrary too, but in doubt
I decided to be inclusive). The final network had 58 nodes, and 250 edges.&lt;/p&gt;

&lt;p&gt;Here are the top most important ones, based on their eigenvector centrality:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Word&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Centrality&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;ecology&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;biodiversity&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.94&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;ecological&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.70&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;human&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.45&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;environment&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.43&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;loss&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.40&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;wetland&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.36&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;environmental&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.35&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;forest&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.34&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;wildlife&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.33&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;If you want to see the other words, you can &lt;a href=&quot;http://dx.doi.org/10.6084/m9.figshare.827286&quot;&gt;get the &lt;code&gt;graphml&lt;/code&gt; file from
&lt;em&gt;figshare&lt;/em&gt;&lt;/a&gt;. So here is the recipe. If you want to engage with the
public, these are the topics of interest. And they paint a quite clear picture:
what is the role of human in biodiversity loss at the global scale? As I assume
that the volume of non-ecologists is orders of magnitude larger than the volume
of ecologists, these keywords are most likely what is discussed.&lt;/p&gt;

&lt;p&gt;Here is finally a visualization of the network. There is a clearly
non-significant modular structure, but I’ve nonetheless colored the nodes to
better illustrate the relationships:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/tw-ecol-concepts.png&quot; alt=&quot;The network&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Interestingly (the layout method groups nodes that are close to each other),
there seems to be the “sustainability/ecosystem services” topics
on one side (bottom-left), and the “conservation” topics on the
other side (top-right).&lt;/p&gt;

&lt;p&gt;I’ll keep on running this model from time to time, but I think there is a good
opportunity to design informed strategies for communication with the public.
There is not much effort in collecting these data, and we (scientists) can help
by communicating in issues in which their is a broad interest. And I may end up
doing a best-of of the undergrads complaining on Twitter about how &lt;em&gt;Ecology
101&lt;/em&gt; is hard, that is fun too.&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>An additive partition of species-level specificity</title>
     <link href="http://timotheepoisot.fr/2013/10/15/specificity-range-measures/"/>
    <updated>2013-10-15T00:00:00-04:00</updated>
    <content type="html">&lt;p&gt;A while ago, we published a paper in &lt;em&gt;Methods in Ecology &amp;amp; Evolution&lt;/em&gt;,
&lt;a href=&quot;http://timotheepoisot.fr/2012/01/19/measuring-ecological-specificity/&quot;&gt;comparing different ways to estimate ecological
specificity&lt;/a&gt;
on binary (presence/absence) and quantitative data. All the measures we
review, and the one we introduce, work in the same way: for an organism,
species, population, you have an array &lt;strong&gt;P&lt;/strong&gt; of its performances across &lt;em&gt;R&lt;/em&gt;
different environments, which is (1) sorted decreasingly, and (2) ranged so
that &lt;strong&gt;P&lt;/strong&gt;[1] = 1. In this paper, we recommend to use either &lt;em&gt;RR&lt;/em&gt; (which is
a modification of Schoener’s generality), and &lt;em&gt;PDI&lt;/em&gt; (which is first
formally introduced in this paper), which measures how fast
performance decreases when you move away from the optimal environment
(the faster it decays, the more specialized you are).&lt;/p&gt;

&lt;p&gt;The main advantage of &lt;em&gt;PDI&lt;/em&gt; is that it relates extremely well to the
&lt;em&gt;definition&lt;/em&gt; of what specificity is: a rapid decay of performance on resources
which are not your own optimum (regardless of the &lt;em&gt;absolute&lt;/em&gt; performance on
this optimal resource, which is why we set &lt;strong&gt;P&lt;/strong&gt;[1] = 1). &lt;em&gt;PDI&lt;/em&gt; is
nothing more that the sum of performance lost by not being on the optimal
resource, divided by the number of non-optimal resources. Somewhere in the end
of the paper, we write that when the data are binary, &lt;em&gt;RR&lt;/em&gt; and &lt;em&gt;PDI&lt;/em&gt; are
equivalent. For some reason that still eludes me, the demonstration did not
make its way in the final version of the paper. So let’s start with it. First,
for an organism of which the performances are measured in &lt;em&gt;R&lt;/em&gt;
environments, of which it has a performance higher than 0 in &lt;em&gt;r&lt;/em&gt;, we
define &lt;em&gt;RR&lt;/em&gt; as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; RR = \frac{R-r}{R-1} &lt;/script&gt;

&lt;p&gt;and &lt;em&gt;PDI&lt;/em&gt; as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; PDI = \frac{\sum_{i=2}(\mathbf{P}_1-\mathbf{P}_i)}{R-1} &lt;/script&gt;

&lt;p&gt;It’s easy to prove that if all values of &lt;strong&gt;P&lt;/strong&gt; are either 0 or 1, then &lt;em&gt;PDI&lt;/em&gt;
= &lt;em&gt;RR&lt;/em&gt;. In this situation, the species in question has &lt;em&gt;r&lt;/em&gt; times 1 in &lt;strong&gt;P&lt;/strong&gt;,
and &lt;em&gt;R-r&lt;/em&gt; times 0 in &lt;strong&gt;P&lt;/strong&gt;. In other words, for the first &lt;em&gt;r&lt;/em&gt; elements of
&lt;strong&gt;P&lt;/strong&gt;, &lt;strong&gt;P&lt;/strong&gt;[1]-&lt;strong&gt;P&lt;/strong&gt;[i] = 0, and for the remaining (&lt;em&gt;R-r&lt;/em&gt;) elements,
&lt;strong&gt;P&lt;/strong&gt;[1]-&lt;strong&gt;P&lt;/strong&gt;[i] = 1. The numerator of &lt;em&gt;PDI&lt;/em&gt; is thus &lt;em&gt;R-r&lt;/em&gt;, so the
expression of &lt;em&gt;PDI&lt;/em&gt; is the same as the expression of &lt;em&gt;RR&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Previously, we and others discussed the fact that specificity ought to be
separated in its “interactions” and “impacts” components, &lt;em&gt;i.e.&lt;/em&gt; (i) how many
resources do I exploit, and (ii) how are my performances distributed. With &lt;em&gt;RR&lt;/em&gt;
and &lt;em&gt;PDI&lt;/em&gt;, it might seem that we have the adequate tool to measure both sides
of the specificity. There’s more to do with these measures, though. Because
&lt;em&gt;RR&lt;/em&gt; is included in &lt;em&gt;PDI&lt;/em&gt; (it’s easy to show that &lt;em&gt;PDI&lt;/em&gt; &amp;amp;geq; &lt;em&gt;RR&lt;/em&gt;), &lt;em&gt;PDI&lt;/em&gt; also
measures an “association” component of specificity. But then again, the
specificity of impact makes sense if you first consider the specificity of
associations before. So we can start thinking of this problem as an additive
partition of specificity:&lt;/p&gt;

&lt;p&gt;Specificity = associations + impacts&lt;/p&gt;

&lt;p&gt;Luckily, we know that &lt;em&gt;RR&lt;/em&gt; measures the specificity of associations, and the
impacts are accounted for by &lt;em&gt;PDI&lt;/em&gt;, so in measurable terms, the above becomes&lt;/p&gt;

&lt;p&gt;&lt;em&gt;PDI&lt;/em&gt; = &lt;em&gt;RR&lt;/em&gt; + &lt;em&gt;I&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This additive partition makes sense, because if you go back to the
demonstration of &lt;em&gt;PDI = RR&lt;/em&gt;, it’s straightforward that whenever performances
are different across resources, the first &lt;em&gt;r&lt;/em&gt; elements of &lt;strong&gt;P&lt;/strong&gt;[1]-&lt;strong&gt;P&lt;/strong&gt;[i]
will be &lt;em&gt;greater&lt;/em&gt; than 0, so the numerator will be &lt;em&gt;greater&lt;/em&gt; than &lt;em&gt;R-r&lt;/em&gt;, so
&lt;em&gt;PDI&lt;/em&gt; will be superior or equal to &lt;em&gt;RR&lt;/em&gt;. How much greater it will be is the
importance of different performances on specificity. Or in other words, when
you do not have informations to measure specificity of impacts, all of the
specificity is because of associations.&lt;/p&gt;

&lt;p&gt;Now what? Well, we can start measuring how much of the total specificity
(&lt;em&gt;PDI&lt;/em&gt;) is due to specificity of associations only (&lt;em&gt;RR&lt;/em&gt;/&lt;em&gt;PDI&lt;/em&gt;), and how much
                                                          is due to specificity
                                                          of impacts only
                                                          (&lt;em&gt;I&lt;/em&gt;/&lt;em&gt;PDI&lt;/em&gt;). As far
                                                                as I can tell,
                                                                the couple
                                                               &lt;em&gt;PDI&lt;/em&gt;-&lt;em&gt;RR&lt;/em&gt; is
                                                               the only pair of
                                                               measures that
                                                               allow to do that
                                                               (though there
                                                               are other
                                                               approaches) in
                                                               a context where
                                                               you can show
                                                               that one measure
                                                               is a component
                                                               of the other.
                                                               Here is a &lt;code&gt;R&lt;/code&gt;
                                                               function to do
                                                               it using the
                                                               &lt;code&gt;ESM&lt;/code&gt; package
                                                               (&lt;a href=&quot;https://r-forge.r-project.org/R/?group_id=593&quot;&gt;from
                                                               R-Forge&lt;/a&gt;).&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;ESM&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

sap &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;P&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
   Spe &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; pdi&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;P&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
   Ass &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; rr&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;P&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
   Imp &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; Spe &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; Ass
   &lt;span class=&quot;kr&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;list&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
      specificity  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; Spe&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      associations &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; Ass&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      impacts      &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; Imp&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      assoc_rel    &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; Ass &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; Spe&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      impac_rel    &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; Imp &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; Spe
      &lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Let’s do some simple examples, and contrast to species with the same number of
resources, but a very high performance on resource 2, or a very low performance
on resource 3:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; unlist&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;sap&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;c&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.999&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
  specificity associations      impacts    assoc_rel    impac_rel 
  &lt;span class=&quot;m&quot;&gt;0.500500000&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;0.500000000&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;0.000500000&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;0.999000999&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;0.000999001&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; unlist&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;sap&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;c&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
  specificity associations      impacts    assoc_rel    impac_rel 
  &lt;span class=&quot;m&quot;&gt;0.9995000&lt;/span&gt;    &lt;span class=&quot;m&quot;&gt;0.5000000&lt;/span&gt;    &lt;span class=&quot;m&quot;&gt;0.4995000&lt;/span&gt;    &lt;span class=&quot;m&quot;&gt;0.5002501&lt;/span&gt;    &lt;span class=&quot;m&quot;&gt;0.4997499&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In the second example, because the performance on the second resource is much
almost zero, the &lt;em&gt;RR&lt;/em&gt; and &lt;em&gt;I&lt;/em&gt; components are almost as important to understand
specificity (whereas it’s not the case in the first example, wherein you can
assume that &lt;strong&gt;P&lt;/strong&gt;[2] = 1 without changing the big picture.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
     <title>R, priority effects, and the meta-package</title>
     <link href="http://timotheepoisot.fr/2013/10/12/r-priority-responsibility/"/>
    <updated>2013-10-12T00:00:00-04:00</updated>
    <content type="html">&lt;p&gt;R packages are a superb opportunity to use new methods, and if anything, we
should only rejoice that there are so many of them in ecology. Yet, there is
a point that occurred to me over recent experiences (reviewing code for a few
papers recently, and reading the help page about &lt;a href=&quot;http://www.inside-r.org/packages/cran/bipartite/docs/PDI&quot;&gt;one of my own metrics
in the &lt;code&gt;bipartite&lt;/code&gt; package&lt;/a&gt;), and that I think is rarely discussed.&lt;/p&gt;

&lt;p&gt;When a R package presenting a series of measures becomes available, it will
become the &lt;em&gt;gold standard&lt;/em&gt; of future analyzes in this field. This is an
extremely strong effect. French students in ecology use the (French-developed)
&lt;code&gt;ade4&lt;/code&gt; package, while people in Québec use the &lt;code&gt;vegan&lt;/code&gt; package (most likely
because of its ties with the &lt;em&gt;Numerical Ecology&lt;/em&gt; book, as Gavin
Simpson mentioned in the comments). There is a priority effect when
a package is released, and metrics that are not implemented in this package,
because they are more difficult to apply, will be less widely used. This is
a central point for methodological research papers. Describing the method is
a small fraction of the work. People are more likely to apply what is
proposed if there is a tool to do it, and as a consequence, (&lt;em&gt;I assume
that&lt;/em&gt;) methods are used more if there is an easy and well-known way to
apply them.&lt;/p&gt;

&lt;p&gt;This is especially true of large-scale packages, that aim to become your single
interface with the metrics and analyzes in a domain. Ecologists are familiar
with &lt;code&gt;bipartite&lt;/code&gt;, &lt;code&gt;vegan&lt;/code&gt;, &lt;code&gt;picante&lt;/code&gt;, &lt;code&gt;ape&lt;/code&gt;, for example. These “mega-packages”
implement a lot of measures, and for this reason, some will look through the
manual to see what kind of analyzes they can do. I most likely still do it
myself, especially so for side-projects where I’m not entirely familiar with
the methodological literature yet. So based on my experience, this is
particularly problematic for newcomers to a field, because when you don’t know,
you assume that the default values were chosen as defaults by
someone knowing what he was doing. Then I remember the &lt;a href=&quot;http://www.python.org/dev/peps/pep-0020/&quot;&gt;&lt;em&gt;Zen of
Python&lt;/em&gt;&lt;/a&gt;: &lt;em&gt;“In the face of ambiguity, refuse the temptation
to guess.”&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;And as we all have different sensibilities, it shows in the way we think about
code, and in the way we write it. The default options of a function, for
example, can be a matter of choice, and especially so when this function
becomes as broad as “measure diversity”. This partiality is not an issue when
developing tools that you will use for your own research. But when developing
tools intended for a broad audience, then this code becomes a service, and it
is our duty as service providers that the defaults reflect our own biases the
least, and the current consensus the most.&lt;/p&gt;

&lt;p&gt;This is why extremely big packages &lt;em&gt;can&lt;/em&gt; be a problem under some circumstances:
they break Doug McIlroy’s &lt;em&gt;Unix philosophy&lt;/em&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;This is the Unix philosophy: &lt;em&gt;Write programs that do one thing&lt;/em&gt; and do it
well. &lt;em&gt;Write programs to work together&lt;/em&gt;. Write programs to handle text
streams, because that is a universal interface.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;When we, as users, rely on a big package to do our work, we assume that every
component of this package is (i) well implemented, (ii) conform to the original
paper, and (iii) up-to-date. Given the frequency of commits in the biggest
ecological packages, I’m sure this is the case, but it’s worth keeping in mind.
My personal preference goes to using a lot of packages doing a small number of
things. For my two papers relying on heavily on the development of comparison
of new methods, I started by writing the R package (well I started at the
drawing board, but that part is not relevant), then used the package to
perform the analyzes described in the paper. The idea is that whenever someone
will (hopefully) read the paper, there will be a package doing &lt;em&gt;only&lt;/em&gt; what is
described in the paper.&lt;/p&gt;

&lt;p&gt;And I understand that some people would rather have one big package doing
everything they need. There are arguments for that of course, namely the fact
that with as many users, errors are most likely to be uncovered, and the
quality of the package will increase (and the state of the R packages in
ecology tends to confirm that). But on the other hand, when you increase
the number of pieces, you increase the probability that one of them will behave
in a way you would not have anticipated. With this regard, packages that
require you to do a lot of small steps by hand have a great advantage, you know
what is happening in real time (then again, I like C and doing every thing by
hand, so perhaps I just enjoy hurting myself).&lt;/p&gt;

&lt;p&gt;In any case, the “default” behavior of programs is something that should be
held under intense scrutiny by the community, and improved code review will
definitely help. This is also where big packages can somehow escape the system:
even if they are reviewed formally (as opposed to being reviewed informally,
which they are in real time as people use them), this will not happen for
each release, and some new releases may introduce things that can be argued
against. In short, my point is: R packages (or packages in other languages, but
you get the idea) tend to rapidly represent the “canon” of the analyzes
to perform, and for this reason, we should always keep a critical eye on them.
Also, keep on writing open-source code, that will enrich the code base
available to the community.&lt;/p&gt;

&lt;p&gt;With that in mind, what would my &lt;em&gt;ideal&lt;/em&gt; super-big package be? Ideally, it
would only be a wrapper around other packages, each doing a single task, &lt;em&gt;Unix
philosophy&lt;/em&gt;-style. Proudly following the ecological tradition of sticking
&lt;em&gt;meta&lt;/em&gt; to every non-meta thing, it would obviously be called a &lt;em&gt;meta-package&lt;/em&gt;.
It would automate the process of taking data from one format to the other, and
propose pipelines to do automated analysis, but with users checking each step
of the process. As such a package would glue together other programs, there
will be little development required. The role of the maintainers, however,
would be to vet the new releases of the packages, find suitable additions,
and so forth. This would be a good example of the community coming
together to merge disparate tools. Social coding platforms allow to do
this almost effortlessly, and it would have the benefit of showing &lt;em&gt;how
the sausage is made&lt;/em&gt;, since each individual package would be usable on its
own. This would also shift the balance towards a system in which there is
a strict one paper / one package relationship, which I think would
considerably clarify the type of analyzes included in a package, in
addition to matching these analyzes to the primary literature.&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>Inferring the structure of food webs</title>
     <link href="http://timotheepoisot.fr/2013/09/21/predicting-network-structure/"/>
    <updated>2013-09-21T00:00:00-04:00</updated>
    <content type="html">&lt;p&gt;We’ve just published a paper in &lt;em&gt;Methods in Ecology and Evolution&lt;/em&gt;, about the
&lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12103/abstract&quot;&gt;inference of food web structure based on species trait data&lt;/a&gt;. That’s
a seriously cool result (we think). There is a serious challenge when you work
with food webs: you need to know which species are interacting, and to do so,
you need to observed interactions in the fields. It’s challenging, because
it must be done extensively, so as not to miss interactions.&lt;/p&gt;

&lt;p&gt;But on the other hand, there are well described relationships between traits of
interacting species. In the particular case of food webs, notably, there is
a log-log relationship between the body size of a predator and the body size of
its prey. The existence of this relationship can be used to, given
a distribution of body sizes, predict the interactions within a species
assemblage.&lt;/p&gt;

&lt;p&gt;So what we have been doing, is designing a statistical method to, given a list
of species and body size, callibrate a model of food web structure, to predict
the interactions. As we discuss in the paper, the more traits you put in your
prediction, the better it will get. Using a dataset of fishes, we generated
a convicing network using only body size and bathymetry.&lt;/p&gt;

&lt;p&gt;We think this result is cool, because by opposition to the “observational”
method of constructing food webs, you only need to know (well) a small number
of interactions. As we show in the paper, whenever you have a high R² of the
trait-trait-interaction relationship, the infered network is close to the
observed one. These methods can therefore allow to generate rough estimates of network structure.&lt;/p&gt;

&lt;p&gt;Interestingly, they will also help in the generation of predictions. As we
illustrate in the paper, we can tweak the body size distribution, and see how
much the network structure changes. For example, this can help simulate the
effect of body size decrease through over-fishing, or the extinction of the
larger species. There is still a bit of work to do to be able to predict the
structure of other types of networks, but it was definitely comforting to see
that, even with straightforward statistics, we were able to achieve it.&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>Is programming an acquired taste?</title>
     <link href="http://timotheepoisot.fr/2013/09/11/programming-innate-acquired/"/>
    <updated>2013-09-11T00:00:00-04:00</updated>
    <content type="html">&lt;p&gt;Two weeks ago, the whole lab headed up to a remote place in the Rimouski
countryside for a summers school on &lt;em&gt;Ecological Modeling&lt;/em&gt;. It was a whole lot
of fun, and a really good way to get back to some things I’ve always wanted to
study more in depth. So far, so good. Most of the days were courses in the
morning, and programming in the afternoon. There were also some pen-and-paper
model solving, but I won’t talk much about these.&lt;/p&gt;

&lt;p&gt;While the students were sweating on the programming problems, we discussed the
fact that programming is maybe an innate skill. Not in the sense that some
people are unable to learn how to code functional things, but in the sense that
some people find it intuitive to express things in terms of &lt;code&gt;for&lt;/code&gt;, &lt;code&gt;while&lt;/code&gt;,
&lt;code&gt;if&lt;/code&gt;, and so forth (so forth is &lt;em&gt;not&lt;/em&gt; a valid algorithmic structure). That
may be true, that some people will find it easier to split up a large
problem in a series of short instructions. If you can do that intuitively,
then you’ll probably have no problem structuring your code.&lt;/p&gt;

&lt;p&gt;But this particular skill can be trained, I think. One of the things I asked of
the students was to code something implementing Williams &amp;amp; Martinez &lt;em&gt;niche
model&lt;/em&gt; of food webs. The title of the assignment may be “Write a program
implementing the NM in R”. I took the opportunity of turning that into an
exercise about how to organize code. The whole problem can be easily
sub-divided into a series of smaller problems. In this case, we first need to
generate species, then to find out the interactions between them. The first
step, of generating species, itself involves several sub-steps, that can each
go into a function, or can be handled by logical tests.&lt;/p&gt;

&lt;p&gt;Perhaps there will be a &lt;em&gt;happy few&lt;/em&gt; that will take this series of steps by
themselves. Looking back on the first programs I wrote (I am unlucky enough to
have kept some of my spaghetti code from my first year of Masters, …),
I’m definitely not one of these people. As in most things, the key to
developing a feeling of how to organize things will come with practice, and
thinking about what you felt comfortable with. Which is why I always
encourage people to &lt;a href=&quot;http://timotheepoisot.fr/2013/04/12/learn-code-ecology/&quot;&gt;write code when they want to learn&lt;/a&gt;. I seriously
don’t think there is a better way to increase your skills.&lt;/p&gt;

&lt;p&gt;So, is programming an acquired taste? Probably. It may seems frustrating at
first to need to specify things clearly at a very small scale. Some people may
call it intuitive, and be comfortable with the &lt;code&gt;if&lt;/code&gt;s and the &lt;code&gt;while&lt;/code&gt;s really
quickly, but I don’t think these are majority. And that might explain why it’s
not uncommon to hear students say that they aren’t able to code well (aside
from the fact that, well, monkeys and typewriters…). Learning how to
code is like learning a language with a different grammatical structure. On
your first day, Python and &lt;a href=&quot;http://en.wikipedia.org/wiki/Brainfuck&quot;&gt;brainfuck&lt;/a&gt;
look awfully similar. Things you conceptualize easily will not translate well
in your editor because you need to use a different structure of thought to
express them. The more you practice, the more natural it will seem. For this
reason, I don’t really believe in programming classes (for biologists, I don’t
know how it goes in other majors) in which you only need to write-down
some code, press enter, and see that it does what your instructor says it does.
Letting students experiment, and fail, and sort out their experiences of what
worked, what did not, and what they felt comfortable with, could probably do
a lot to improve coding literacy.&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>Teach more maths to the undergrads!</title>
     <link href="http://timotheepoisot.fr/2013/08/28/lack-quantitative-training/"/>
    <updated>2013-08-28T00:00:00-04:00</updated>
    <content type="html">&lt;p&gt;Fred Barraquand, a bunch of INNGE-and-friends-of-INNGE people, and I, just
published a &lt;a href=&quot;https://peerj.com/preprints/53/&quot;&gt;preprint&lt;/a&gt; at &lt;em&gt;Peer J&lt;/em&gt; about quantitative training in
early-career ecologists (or rather, the lack thereof). Talking about how much
maths is needed during training is all the rage in the ecological community,
and both sides of the argument have really good arguments.&lt;/p&gt;

&lt;p&gt;So Fred decided to do a survey of early-career (and older) ecologists through
&lt;em&gt;ECOLOG-L&lt;/em&gt;. Quoting directly from the abstract, this is what we found:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We found a clear self-perceived lack of quantitative training: &lt;strong&gt;75% are not
satisfied with their understanding of mathematical models&lt;/strong&gt;; 75% feel the level
of mathematics was “too low” in their ecology classes; 90% wanted more
mathematics classes for ecologists; and 95% more statistics classes.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;There are a lot of number to process, but basically all point to the same
message: with a few more years of experience after your undergraduate degree,
you wish you have studied more maths (it’s especially true for me). We
conclude the paper by exploring recommendations about how to (re)design
curriculum using the results from this survey.&lt;/p&gt;

&lt;p&gt;I discussed this result with my B.Sc. class last fall. We had a fun exchange,
and over time, the polarization between animal-watchers and number-crunchers
(the 2 or 3 of them) decreased. But here is the fun thing. When I asked the
students whether the found plausible that they’ll wish for strong
quantitative training in a few years, they said yes. Immediately afterwards,
when I asked what they would do if we increased the part of quantitative
training up to 30% of all classes, as survey respondent suggested. To a vast
majority, they would not enroll.&lt;/p&gt;

&lt;p&gt;So, it seems like we’ll need to sneakily teach quantitative skills…&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>In defense of narrative reviews</title>
     <link href="http://timotheepoisot.fr/2013/08/24/in-defense-narrative-reviews/"/>
    <updated>2013-08-24T00:00:00-04:00</updated>
    <content type="html">&lt;p&gt;Early in July, Christopher Lortie published a really great preprint on &lt;em&gt;PeerJ&lt;/em&gt;,
about the &lt;a href=&quot;https://peerj.com/preprints/39/&quot;&gt;opportunities of systematic reviews for ecology&lt;/a&gt;. It’s
extremely insightful, and a good read. The abstract starts by &lt;em&gt;Narrative
reviews are dead&lt;/em&gt;. No they’re not, nor shouldn’t they be! &lt;em&gt;Narrative&lt;/em&gt; reviews are those we are used to read now: a story built on the
collection of some pieces of litterature. On the other hand, systematic reviews
or meta-analyses are, well, systematic, and try to reach a consensus (at least
a generalizable result) through the analysis of everything published on
a particular topic (I abusively generalize, but go read the paper and you’ll
get the idea).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;There is something fascinating about science. One gets such wholesale returns of conjecture out of such a trifling investment of fact.&lt;/em&gt; &lt;br /&gt;
Mark Twain&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I get the idea that narrative reviews are more likely to reflect the author(s)
personal biases or interests, and in our quest for absolute impartiality, it
would make sense to get rid of this. This is the whole point of Chris’s
paper: as the goal of a review is to give an overview of the
state-of-the-art in a particular field, then non-narrative reviews are the
&lt;em&gt;better&lt;/em&gt; tool. Nonetheless, I think this is an over-simplification of the
way people &lt;em&gt;use&lt;/em&gt; review papers.&lt;/p&gt;

&lt;p&gt;As a Ph.D. candidate, &lt;em&gt;narrative&lt;/em&gt; reviews helped me a lot when I was trying to
get an idea of the history of the field. Being able to understand how current
ideas emerged from previous observations and results, and seeing which papers
influenced which authors, was important when I had to develop my own research
questions. I won’t spend time on the argument that narrative reviews are great
teaching material, and that it’s a gentler introduction to a field to be walked
through a concept rather than to read through tables of ANOVA. I enjoy these
much more when I have an idea of the “story” behind.&lt;/p&gt;

&lt;p&gt;Essentially, narrative reviews should not be discarded because they serve
a different purpose from systematic reviews. Let’s take the example of the
&lt;a href=&quot;http://en.wikipedia.org/wiki/Rare_biosphere&quot;&gt;&lt;em&gt;rare biosphere&lt;/em&gt;&lt;/a&gt; in environmental microbiology. For several
historical reasons, it has been hypothesized that the distribution of
biodiversity has a long-tail, with a lot of species being in extremely low
abundances. Classical sampling and enumeration technique only described the tip
of the iceberg. Fast forward a few years later, and the existence of the rare
biosphere is well established, and people start questioning its impact in
ecosystem processes, among other things. How we switched from “it probably
exists” to “we need to understand what it’s doing” is best understood with
a little bit of narration. Specifically, the development of molecular biology
methods, and recently high-throughput sequencing, increased our detection
ability by order of magnitudes. The emergence of new tools (which in the
perspective of people like &lt;a href=&quot;http://www.scribd.com/doc/28780545/Gutting-Bachelard-s-Philosophy-of-Science-1987&quot;&gt;Bachelard, only reflects the emergence of new
theories&lt;/a&gt; that progressively materialized) allowed a switch in the way
people studied rare biosphere. A &lt;em&gt;narrative&lt;/em&gt; review of the question will likely
put this element forward.&lt;/p&gt;

&lt;p&gt;A systematic review will hold different informations. While the narrative
review aks &lt;em&gt;How did we get there?&lt;/em&gt;, the systematic review asks &lt;em&gt;Where are we
now?&lt;/em&gt;. They give different answers, but it’s hard to argue that one of these
questions has more merit than the other. Interestingly, more and more reviews
conclude by asking &lt;em&gt;Where to next?&lt;/em&gt;. Both narrative and systematic reviews can
bring different elements, and thus will likely bring different responses. This
multiplicity of points of views should not be so rapidly dismissed. Narrative
reviews should be continued &lt;em&gt;because&lt;/em&gt; they are often not entirely impartial,
reflects biases or personnal preferences, and because they tell
stories. Once we are familiar with this story, and once we know the
different interpretations that people make of the same data, it’s time
to go read the systematic reviews, and the meta-analyses. I appreciate
that people will enjoy one of these more than the other, or would
prefer to read statistics before naration. But I think we should
continue reading, and writing, narrative reviews.&lt;/p&gt;

&lt;p&gt;As a final point, whatever you may think of the issue, go read the “companion”
paper about the &lt;a href=&quot;https://peerj.com/preprints/38/&quot;&gt;&lt;em&gt;interpretation&lt;/em&gt;&lt;/a&gt; of meta-analyses in ecology. It’s
a really good introduction.&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>Network structure of obligate and facultative parasites</title>
     <link href="http://timotheepoisot.fr/2013/08/20/network-structure-obligate-facultative-parasites/"/>
    <updated>2013-08-20T00:00:00-04:00</updated>
    <content type="html">&lt;p&gt;We have a new paper &lt;a href=&quot;http://dx.doi.org/10.1017/S0031182013000851&quot;&gt;online at &lt;em&gt;Parasitology&lt;/em&gt;&lt;/a&gt;, on the differences of
the structure between rodents hosts, and their obligates of facultatives
parasites. We had data from a really cool rodents-ectoparasites system, in
which the same hosts have both facultative and obligate parasites. These data
were also collected in different locations, and at different times.&lt;/p&gt;

&lt;p&gt;There are two important things in the results. First, the networks of obligate
and facultative parasites look &lt;em&gt;nothing&lt;/em&gt; alike. One (obligate) is highly
modular and anti-nested, and the other (facultative) is highly nested but not
particularly more or less modular. But when you look at all types of parasites
together, the resulting networks are both more moudular &lt;em&gt;and&lt;/em&gt; more nested than
expected by chance. The take-home of this particular result is: “parasitism” is
a vague notion, and we should not be too surprized when lumping contrasted
ecological strategies makes weird results emerge (also, we should focus on how
different functional groups affect network properties).&lt;/p&gt;

&lt;p&gt;The second part of the result is most likely more appealling to
parasitologists: we show that the networks of obligate parasites vary less in
space and time that the network of facultative ones. Not too suprising when you
think about it long enough: facultative parasites are mostly opportunisitc, and
thus they will probably pick their hosts more randomly (without less
constraints) than obligate ones. There’s also the fact that facultative
parasites tend to occupy sites within the hosts that require less stringent
adaptations. But the key message is still the same: when we lump different
classes of organisms together in a single network, it’s important to quantify
how much each contribute to the overall properties.&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>Complexity and connectance of ecological networks</title>
     <link href="http://timotheepoisot.fr/2013/08/19/connectance-complexity/"/>
    <updated>2013-08-19T00:00:00-04:00</updated>
    <content type="html">&lt;p&gt;So my &lt;a href=&quot;http://timotheepoisot.fr/2013/06/19/notes-on-network-complexity/&quot;&gt;blog post on ecological complexity in networks&lt;/a&gt; turned into
a manuscript, now online as a preprint at &lt;a href=&quot;https://peerj.com/preprints/50/&quot;&gt;&lt;em&gt;PeerJ&lt;/em&gt;&lt;/a&gt;. We’ll send it up for
review (at &lt;em&gt;PeerJ&lt;/em&gt; also) in a while, but feel free to read it and give us
feedback using the &lt;a href=&quot;https://github.com/tpoisot/ms_connectance_complexity/issues&quot;&gt;github issues tracker&lt;/a&gt;. We’d like that very much,
actually. And as the github repository is public, feel free to
fork/edit/push modifications if you have something to contribute to
the paper.&lt;/p&gt;

&lt;p&gt;In a nutshell; we argue that connectance is still a central property of
networks. For one thing, (i) it constrains how much different networks exists
for a given species number, which was the point of the original post. But more
importantly, (ii), because a given connectance implies a given number of
interactions, connectance imposes structural constraints on networks
properties. Or in other words, all important moments of the degree distribution
vary with connectance. And it works quite well with Erdos-Renyi graphs, and
with the famous “niche” model of food webs.&lt;/p&gt;

&lt;p&gt;It’s kinda cool, because connectance is &lt;em&gt;simple&lt;/em&gt; to measure, and even people
that no background in network analysis will get what it means. It also means
that from a purely statistical point of view, any effect of the degree
distribution must be controlled for an effect of connectance. &lt;/p&gt;

&lt;p&gt;&lt;em&gt;P.S.&lt;/em&gt;: This is a good example of &lt;a href=&quot;http://timotheepoisot.fr/2013/08/05/codelust/&quot;&gt;Codelust&lt;/a&gt; in practice. The
original script were written over a particularly greasy and disappointing club
sandwich eaten alone in my office, so at least something productive came out of
this particularly bleak view of the academic daily life…&lt;/p&gt;

</content>
  </entry>
  
  <entry>
     <title>Writing manuscripts in Linux (like a boss)</title>
     <link href="http://timotheepoisot.fr/2013/08/18/writing-linux-like-a-boss/"/>
    <updated>2013-08-18T00:00:00-04:00</updated>
    <content type="html">&lt;p&gt;Hey, it’s been a year since I &lt;a href=&quot;http://timotheepoisot.fr/2012/08/03/new-linux-setup/&quot;&gt;switched to Linux&lt;/a&gt;. I’ve tried a few
different distros, and finally settled on &lt;a href=&quot;https://www.archlinux.org/&quot;&gt;Arch Linux&lt;/a&gt; with
&lt;a href=&quot;http://openbox.org/&quot;&gt;OpenBox&lt;/a&gt;. It’s ligthweight, uncluttered, and I love. But that’s not what
I’m going to talk about.&lt;/p&gt;

&lt;p&gt;I may have mentionned in the past that I used &lt;em&gt;Sublime Text 2&lt;/em&gt;. During my quest
for ever-increasing minimalism, I’ve made the switch to &lt;code&gt;vim&lt;/code&gt;. And I now have
a &lt;em&gt;cool&lt;/em&gt; writing setup. Most of what I do is writing markdown files, and using
makefiles to use pandoc to convert them to PDF (read more about it
&lt;a href=&quot;http://timotheepoisot.fr/2013/05/18/make-pandoc/&quot;&gt;here&lt;/a&gt;). The only thing that missed was a lightweight PDF reader,
able to auto-refresh things. I have now found &lt;a href=&quot;http://pwmt.org/projects/zathura/&quot;&gt;&lt;em&gt;zathura&lt;/em&gt;&lt;/a&gt;. I am supper happy.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;zathura&lt;/em&gt; is command-line based, and uses keyboard for interaction. So whenever
I am working on a document in a terminal (&lt;code&gt;rxvt-unicode&lt;/code&gt;, in case you wonder,
with the &lt;em&gt;excellent&lt;/em&gt; font &lt;a href=&quot;http://damieng.com/blog/2008/05/26/envy-code-r-preview-7-coding-font-released&quot;&gt;Envy Code R&lt;/a&gt;), I just need to do a quick
&lt;code&gt;zathura my-doc.pdf&lt;/code&gt;, and I can see the output. Because &lt;em&gt;zathura&lt;/em&gt;
auto-refreshes things, whenever I &lt;code&gt;make pdf&lt;/code&gt;, the output is up to date. Just
like that.&lt;/p&gt;

&lt;p&gt;And the point is: the productivity boost is amazing. I do everything from within the terminal (or rather, terminals, I have a few of them open at any time). And it’s fast, ligthweight, and &lt;em&gt;responsive&lt;/em&gt;. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;And just in case you are curious&lt;/strong&gt;, a list of the &lt;em&gt;vim&lt;/em&gt; plugins I use: &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/tpope/vim-pathogen&quot;&gt;pathogen&lt;/a&gt; to easily install plugins&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/airblade/vim-gitgutter&quot;&gt;vim-gitgutter&lt;/a&gt; to see how my local file differs from the git version&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/vim-pandoc/vim-pandoc&quot;&gt;vim-pandoc&lt;/a&gt; for a lot of pandoc-related stuff, including &lt;em&gt;bibtex reference auto-completion&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
  </entry>
  
</feed>
